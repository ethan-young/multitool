[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 multitool authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ethan Young. Author, maintainer. Stefan Vermeent. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Young E, Vermeent S (2023). multitool: Tools Running Multiverse Style Analyses. R package version 0.0.0.9000, https://ethan-young.github.io/multitool/.","code":"@Manual{,   title = {multitool: Tools for Running Multiverse Style Analyses},   author = {Ethan Young and Stefan Vermeent},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://ethan-young.github.io/multitool/}, }"},{"path":"/index.html","id":"multitool","dir":"","previous_headings":"","what":"Tools for Running Multiverse Style Analyses","title":"Tools for Running Multiverse Style Analyses","text":"goal multitool provide set tools designing running multiverse-style analyses. goal package create incremental workflow slowly building , keeping track , unpacking multiverse analyses results. designed multitool help users take single use case (e.g., single analysis pipeline) expand workflow include alternative versions analysis. example, imagine like take data, remove outliers, transform variables, run linear model, post-hoc analysis, plot results. multitool can take theses tasks transform specification blueprint, provides instructions running analysis pipeline. functions designed play nice tidyverse require using base R pipe |>. makes easy quickly convert single analysis multiverse analysis.","code":""},{"path":"/index.html","id":"basic-components","dir":"","previous_headings":"","what":"Basic components","title":"Tools for Running Multiverse Style Analyses","text":"vision multiverse workflow contains three parts. Base data: original dataset waiting processing specification blueprint: aka specification grid. blueprint/map/recipe whatever want call . instructions . Multiverse results: table results feeding base data blueprint. defining feature multitool saves pipeline code. allows user grab code produces result inspect accuracy, errors, simply peace mind. quickly grabbing code, user can iterate creating blueprint checking code works intended. multitool allows user model data however ’d like. user responsible loading relevant modeling packages. Regardless model choice, multitool capture code build pipeline. Finally, multiverse analyses originally intended look model parameters shift function arbitrary analysis decisions. However, computation might change depending slice dice data. reason, also built functions computing descriptive, correlation, reliability analysis alongside particular modelling pipeline.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Running Multiverse Style Analyses","text":"can install development version multitool GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"ethan-young/multitool\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Tools for Running Multiverse Style Analyses","text":"","code":"library(tidyverse) library(multitool)"},{"path":"/index.html","id":"the-base-data","dir":"","previous_headings":"","what":"The base data","title":"Tools for Running Multiverse Style Analyses","text":"Image data several predictor variables, moderators, covariates, dependent measures. want know predictors (ivs) interact moderators (mods) predict outcome (dvs). three versions predictor measuring construct different way. addition, collected messy data real world (really let’s pretend), idea exclusions might need make (e.g., include1, include2, include3).","code":"the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )"},{"path":"/index.html","id":"create-a-blueprint","dir":"","previous_headings":"","what":"Create a blueprint","title":"Tools for Running Multiverse Style Analyses","text":"Say don’t know much new exciting area research. want maximize knowledge also want systematic. One approach specify reasonable analysis pipeline. Something looks like following: valid alternative alternatives pipeline? example, using iv2 instead iv1 using two exclusion criteria instead three? sensible approach copy code , paste , edit different decisions. quickly become tedious. adds many lines code, many new objects, difficult keep track systematic way. Enter multitool. multitool, analysis pipeline can transformed grid – specification blueprint – exploring combinations sensible data decisions pipeline. designed leverage already written code (e.g., filter statement ) create multiverse data analysis pipelines.","code":"# Filter out exclusions filtered_data <-    the_data |>    filter(     include1 == 0,           # --     include2 != 3,           # Exclusion criteria     scale(include3) > -2.5   # --   )  # Model the data my_model <- lm(dv1 ~ iv1 * mod, data = filtered_data)  # Check the results my_results <- broom::tidy(my_model)"},{"path":"/index.html","id":"filtering-specifications","dir":"","previous_headings":"","what":"Filtering specifications","title":"Tools for Running Multiverse Style Analyses","text":"example three exclusion criteria. don’t know important, example, based arbitrary ‘rules thumb’ (may may inherent wisdom) don’t know including/excluding cases valid, can generate combinations: output simple tibble (.e., data.frame) containing three columns. row possible filter: type column refers type blueprint specification (see types filters), group refers variable base data frame (case the_data) filter applies, code column contains code needed execute filter. filtering decisions (e.g., exclusion criteria), ‘nothing’ alternative always generated. example, perhaps observations belong subgroup, include1 == 1. may may good reason exclude cases (depends specific situation). imagine don’t know include . include1 == 1 added add_filters(), ‘nothing’ alternative include1 %% unique(include1) automatically generated can compare including versus excluding cases based criterion.","code":"the_data |>    add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) #> # A tibble: 6 × 3 #>   type    group    code                           #>   <chr>   <chr>    <chr>                          #> 1 filters include1 include1 == 0                  #> 2 filters include1 include1 %in% unique(include1) #> 3 filters include2 include2 != 3                  #> 4 filters include2 include2 %in% unique(include2) #> 5 filters include3 scale(include3) > -2.5         #> 6 filters include3 include3 %in% unique(include3)"},{"path":"/index.html","id":"adding-alternative-analysis-variables","dir":"","previous_headings":"","what":"Adding alternative analysis variables","title":"Tools for Running Multiverse Style Analyses","text":"multiverse-style analyses explore range exclusion criteria alternatives. However, sometimes alternative versions variable also included. social sciences, fairly common many measures roughly construct (.e., measured variable). example, happiness researcher might measure positive mood, life satisfaction, /single item measuring happiness (e.g., ‘happy feel?’). want explore output pipeline differing versions variable, can use add_variables(). output generates tibble add_filters(). row particular decision use particular variable pipeline. contrast filter, however, need tell add_variables() call set variables var_group argument. multitool knows variable name code column different alternative larger set. , var_group = \"ivs\" indicates iv1, iv2, iv3 different versions ivs. used “ivs” way indicating alternative versions main independent variable. can add many variable sets want. example, might also want analyze two versions outcome, dv1 dv2.","code":"the_data |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) #> # A tibble: 3 × 3 #>   type      group code  #>   <chr>     <chr> <chr> #> 1 variables ivs   iv1   #> 2 variables ivs   iv2   #> 3 variables ivs   iv3 the_data |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) #> # A tibble: 5 × 3 #>   type      group code  #>   <chr>     <chr> <chr> #> 1 variables ivs   iv1   #> 2 variables ivs   iv2   #> 3 variables ivs   iv3   #> 4 variables dvs   dv1   #> 5 variables dvs   dv2"},{"path":"/index.html","id":"building-up-the-blueprint","dir":"","previous_headings":"","what":"Building up the blueprint","title":"Tools for Running Multiverse Style Analyses","text":"can harness real power multitool piping specification statements. example, perhaps want explore exclusion criteria alternatives across different versions predictor outcome variables. can simply pipe new blueprint specifications like : Notice now specification blueprint exclusion alternatives variable alternatives.","code":"the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) #> # A tibble: 11 × 3 #>    type      group    code                           #>    <chr>     <chr>    <chr>                          #>  1 filters   include1 include1 == 0                  #>  2 filters   include1 include1 %in% unique(include1) #>  3 filters   include2 include2 != 3                  #>  4 filters   include2 include2 %in% unique(include2) #>  5 filters   include3 scale(include3) > -2.5         #>  6 filters   include3 include3 %in% unique(include3) #>  7 variables ivs      iv1                            #>  8 variables ivs      iv2                            #>  9 variables ivs      iv3                            #> 10 variables dvs      dv1                            #> 11 variables dvs      dv2"},{"path":"/index.html","id":"adding-a-model","dir":"","previous_headings":"","what":"Adding a model","title":"Tools for Running Multiverse Style Analyses","text":"whole point building specification blueprint eventually feed model examine results. can add model blueprint using add_model(). designed add_model() user can simply paste model function. example, call lm() can simply pasted add_model(): , model completely unquoted. also data argument. intentional; multitool tracking base dataset along way (don’t ). Note can still quote model formula, style. make sure add_variables() works properly, add_model() designed interpret glue::glue() syntax. example: allows multitool insert correct version variable specified add_variables() step. Make sure use embrace variable var_group argument add_variables(), example add_model(lm({dvs} ~ {ivs} * mod)). , {dvs} ivs tells multitool insert current version ivs dvs model.","code":"the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(lm(dv1 ~ iv1 * mod)) #> # A tibble: 12 × 3 #>    type      group    code                           #>    <chr>     <chr>    <chr>                          #>  1 filters   include1 include1 == 0                  #>  2 filters   include1 include1 %in% unique(include1) #>  3 filters   include2 include2 != 3                  #>  4 filters   include2 include2 %in% unique(include2) #>  5 filters   include3 scale(include3) > -2.5         #>  6 filters   include3 include3 %in% unique(include3) #>  7 variables ivs      iv1                            #>  8 variables ivs      iv2                            #>  9 variables ivs      iv3                            #> 10 variables dvs      dv1                            #> 11 variables dvs      dv2                            #> 12 models    model    lm(dv1 ~ iv1 * mod) the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"lm(dv1 ~ iv1 * mod)\") #> # A tibble: 12 × 3 #>    type      group    code                           #>    <chr>     <chr>    <chr>                          #>  1 filters   include1 include1 == 0                  #>  2 filters   include1 include1 %in% unique(include1) #>  3 filters   include2 include2 != 3                  #>  4 filters   include2 include2 %in% unique(include2) #>  5 filters   include3 scale(include3) > -2.5         #>  6 filters   include3 include3 %in% unique(include3) #>  7 variables ivs      iv1                            #>  8 variables ivs      iv2                            #>  9 variables ivs      iv3                            #> 10 variables dvs      dv1                            #> 11 variables dvs      dv2                            #> 12 models    model    lm(dv1 ~ iv1 * mod) the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(lm({dvs} ~ {ivs} * mod)) #> # A tibble: 12 × 3 #>    type      group    code                           #>    <chr>     <chr>    <chr>                          #>  1 filters   include1 include1 == 0                  #>  2 filters   include1 include1 %in% unique(include1) #>  3 filters   include2 include2 != 3                  #>  4 filters   include2 include2 %in% unique(include2) #>  5 filters   include3 scale(include3) > -2.5         #>  6 filters   include3 include3 %in% unique(include3) #>  7 variables ivs      iv1                            #>  8 variables ivs      iv2                            #>  9 variables ivs      iv3                            #> 10 variables dvs      dv1                            #> 11 variables dvs      dv2                            #> 12 models    model    lm({dvs} ~ {ivs} * mod)"},{"path":"/index.html","id":"finalizing-the-specification-blueprint","dir":"","previous_headings":"","what":"Finalizing the specification blueprint","title":"Tools for Running Multiverse Style Analyses","text":"final step making blueprint expanding specifications possible combinations. can calling expand_decisions() end blueprint pipeline: result expanded tibble 1 row per unique decision columns major blueprint category. example, alternative variables (predictors outcomes), filters (three exclusion alternatives), model run. Note 3 exclusions (two combinations), 3 versions predictor, 2 versions outcome. means blueprint 2*2*2*3*2 rows. blueprint uses list columns organize information. can view list column using tidyr::unnest(<column name>). example, can look filters: look models: Notice , glue::glue() syntax, different versions predictors outcomes inserted appropriately. can check correspondence using unnest() models variable list columns:","code":"full_pipeline <-    the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(lm({dvs} ~ {ivs} * mod)) |>    expand_decisions()  full_pipeline #> # A tibble: 48 × 4 #>    decision variables        filters          models           #>    <chr>    <list>           <list>           <list>           #>  1 1        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  2 2        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  3 3        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  4 4        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  5 5        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  6 6        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  7 7        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  8 8        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #>  9 9        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #> 10 10       <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 1]> #> # … with 38 more rows 2*2*2*3*2 == nrow(full_pipeline) #> [1] TRUE full_pipeline |> unnest(filters) #> # A tibble: 48 × 6 #>    decision variables        include1      include2      include3       models   #>    <chr>    <list>           <chr>         <chr>         <chr>          <list>   #>  1 1        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  2 2        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  3 3        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  4 4        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  5 5        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  6 6        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  7 7        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #>  8 8        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #>  9 9        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #> 10 10       <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #> # … with 38 more rows full_pipeline |> unnest(models) #> # A tibble: 48 × 4 #>    decision variables        filters          model               #>    <chr>    <list>           <list>           <chr>               #>  1 1        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) #>  2 2        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) #>  3 3        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) #>  4 4        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) #>  5 5        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv3 * mod) #>  6 6        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv3 * mod) #>  7 7        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) #>  8 8        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) #>  9 9        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) #> 10 10       <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) #> # … with 38 more rows full_pipeline |> unnest(c(variables, models)) #> # A tibble: 48 × 5 #>    decision ivs   dvs   filters          model               #>    <chr>    <chr> <chr> <list>           <chr>               #>  1 1        iv1   dv1   <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) #>  2 2        iv1   dv2   <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) #>  3 3        iv2   dv1   <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) #>  4 4        iv2   dv2   <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) #>  5 5        iv3   dv1   <tibble [1 × 3]> lm(dv1 ~ iv3 * mod) #>  6 6        iv3   dv2   <tibble [1 × 3]> lm(dv2 ~ iv3 * mod) #>  7 7        iv1   dv1   <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) #>  8 8        iv1   dv2   <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) #>  9 9        iv2   dv1   <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) #> 10 10       iv2   dv2   <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) #> # … with 38 more rows"},{"path":"/index.html","id":"validate-your-blueprint","dir":"","previous_headings":"","what":"Validate your blueprint","title":"Tools for Running Multiverse Style Analyses","text":"multitool specification blueprint special feature: captures code generates analysis pipelines. special set functions show_code_* prefix allow see code executed single pipeline. example, can look filtering code first decision blueprint: functions allow generate relevant code along analysis pipeline. example, can look model pipeline decision 17 using show_code_model(decision_num = 17): Setting copy argument TRUE allows send code straight clipboard. can paste source console testing/editing. can also run individual decisions test work. See details results.","code":"full_pipeline |> show_code_filter(decision_num = 1) #> the_data |>  #>   filter(include1 == 0, include2 != 3, scale(include3) > -2.5) full_pipeline |> show_code_model(decision_num = 17) #> the_data |>  #>   filter(include1 == 0, include2 %in% unique(include2), scale(include3) > -2.5) |>  #>   lm(dv1 ~ iv3 * mod, data = _) run_universe_model(full_pipeline, decision_num = 1) #> # A tibble: 1 × 2 #>   decision lm_fitted        #>   <chr>    <list>           #> 1 1        <tibble [1 × 5]>"},{"path":"/index.html","id":"implement-your-blueprint","dir":"","previous_headings":"","what":"Implement your blueprint","title":"Tools for Running Multiverse Style Analyses","text":"built full specification blueprint feel comfortable pipeline executed, can implement full multiverse-style analysis. Simply use run_multiverse(<pipeline object>): result another tibble various list columns. always contain list column named specifications containing information generated blueprint. Next, one list column per model fitted, labelled suffix like <function name>_fitted. , ran lm() results contained lm_fitted.","code":"multiverse_results <- run_multiverse(full_pipeline) #> ■■■■■■■■■■■■■■ 44% | ETA: 3s ■■■■■■■■■■■■■■■ #> 48% | ETA: 3s ■■■■■■■■■■■■■■■■■ 52% | #> ETA: 3s ■■■■■■■■■■■■■■■■■■ 56% | ETA: #> 2s ■■■■■■■■■■■■■■■■■■■ 60% | ETA: 2s #> ■■■■■■■■■■■■■■■■■■■■ 65% | ETA: 2s #> ■■■■■■■■■■■■■■■■■■■■■ 67% | ETA: 2s #> ■■■■■■■■■■■■■■■■■■■■■■ 71% | ETA: 2s #> ■■■■■■■■■■■■■■■■■■■■■■■ 75% | ETA: 1s #> ■■■■■■■■■■■■■■■■■■■■■■■■ 77% | ETA: 1s #> ■■■■■■■■■■■■■■■■■■■■■■■■■ 81% | ETA: 1s #> ■■■■■■■■■■■■■■■■■■■■■■■■■■■ 85% | ETA: 1s #> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 90% | ETA: 1s #> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 92% | ETA: 0s #> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 96% | ETA: 0s  multiverse_results #> # A tibble: 48 × 3 #>    decision specifications   lm_fitted        #>    <chr>    <list>           <list>           #>  1 1        <tibble [1 × 3]> <tibble [1 × 5]> #>  2 2        <tibble [1 × 3]> <tibble [1 × 5]> #>  3 3        <tibble [1 × 3]> <tibble [1 × 5]> #>  4 4        <tibble [1 × 3]> <tibble [1 × 5]> #>  5 5        <tibble [1 × 3]> <tibble [1 × 5]> #>  6 6        <tibble [1 × 3]> <tibble [1 × 5]> #>  7 7        <tibble [1 × 3]> <tibble [1 × 5]> #>  8 8        <tibble [1 × 3]> <tibble [1 × 5]> #>  9 9        <tibble [1 × 3]> <tibble [1 × 5]> #> 10 10       <tibble [1 × 3]> <tibble [1 × 5]> #> # … with 38 more rows"},{"path":"/index.html","id":"unpacking-a-multiverse-analysis","dir":"","previous_headings":"","what":"Unpacking a multiverse analysis","title":"Tools for Running Multiverse Style Analyses","text":"two main ways unpack examine multitool results. first using tidyr::unnest() (similar unpacking specification blueprint earlier).","code":""},{"path":"/index.html","id":"unnest","dir":"","previous_headings":"Unpacking a multiverse analysis","what":"Unnest","title":"Tools for Running Multiverse Style Analyses","text":"Inside <model function>_fitted column (lm_fitted), multitool gives us 4 columns. first column always full code pipeline produced results: lm_code. next results passed broom (tidy /glance methods exist). lm, lm_tidy lm_glance. Notice naming convention: <model function>_tidy <model function>_glance. lm_tidy (<model function>_tidy) column gives us main results lm() per decision. include terms, estimates, standard errors, p-values. lm_glance (<model function>_glance) column gives us model fit statistics (among things):","code":"multiverse_results |> unnest(lm_fitted) #> # A tibble: 48 × 7 #>    decision specifications   lm_code         lm_tidy  lm_gla…¹ lm_war…² lm_mes…³ #>    <chr>    <list>           <glue>          <list>   <list>   <list>   <list>   #>  1 1        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  2 2        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  3 3        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  4 4        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  5 5        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  6 6        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  7 7        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  8 8        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  9 9        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #> 10 10       <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #> # … with 38 more rows, and abbreviated variable names ¹​lm_glance, ²​lm_warnings, #> #   ³​lm_messages multiverse_results |> unnest(lm_fitted) |> unnest(lm_tidy) #> # A tibble: 192 × 11 #>    decision specificat…¹ lm_code term  estimate std.e…² stati…³ p.value lm_gla…⁴ #>    <chr>    <list>       <glue>  <chr>    <dbl>   <dbl>   <dbl>   <dbl> <list>   #>  1 1        <tibble>     the_da… (Int…  1.17e-2  0.0642  0.181    0.856 <tibble> #>  2 1        <tibble>     the_da… iv1    6.87e-4  0.0668  0.0103   0.992 <tibble> #>  3 1        <tibble>     the_da… mod    1.33e-3  0.0637  0.0209   0.983 <tibble> #>  4 1        <tibble>     the_da… iv1:…  4.48e-2  0.0675  0.664    0.507 <tibble> #>  5 2        <tibble>     the_da… (Int… -4.44e-2  0.0637 -0.696    0.487 <tibble> #>  6 2        <tibble>     the_da… iv1    6.74e-3  0.0663  0.102    0.919 <tibble> #>  7 2        <tibble>     the_da… mod   -1.54e-2  0.0632 -0.244    0.807 <tibble> #>  8 2        <tibble>     the_da… iv1:…  1.70e-2  0.0670  0.255    0.799 <tibble> #>  9 3        <tibble>     the_da… (Int…  2.24e-2  0.0633  0.354    0.724 <tibble> #> 10 3        <tibble>     the_da… iv2    1.76e-2  0.0654  0.269    0.788 <tibble> #> # … with 182 more rows, 2 more variables: lm_warnings <list>, #> #   lm_messages <list>, and abbreviated variable names ¹​specifications, #> #   ²​std.error, ³​statistic, ⁴​lm_glance multiverse_results |> unnest(lm_fitted) |> unnest(lm_glance) #> # A tibble: 48 × 18 #>    decision specificat…¹ lm_code lm_tidy  r.squ…² adj.r.…³ sigma stati…⁴ p.value #>    <chr>    <list>       <glue>  <list>     <dbl>    <dbl> <dbl>   <dbl>   <dbl> #>  1 1        <tibble>     the_da… <tibble> 1.62e-3 -0.00923  1.06 0.150     0.930 #>  2 2        <tibble>     the_da… <tibble> 5.13e-4 -0.0104   1.05 0.0472    0.986 #>  3 3        <tibble>     the_da… <tibble> 7.75e-3 -0.00304  1.06 0.718     0.542 #>  4 4        <tibble>     the_da… <tibble> 2.00e-3 -0.00885  1.05 0.184     0.907 #>  5 5        <tibble>     the_da… <tibble> 7.06e-5 -0.0108   1.06 0.00650   0.999 #>  6 6        <tibble>     the_da… <tibble> 1.07e-3 -0.00979  1.05 0.0983    0.961 #>  7 7        <tibble>     the_da… <tibble> 1.85e-3 -0.00892  1.06 0.172     0.916 #>  8 8        <tibble>     the_da… <tibble> 4.72e-4 -0.0103   1.05 0.0438    0.988 #>  9 9        <tibble>     the_da… <tibble> 7.92e-3 -0.00278  1.06 0.740     0.529 #> 10 10       <tibble>     the_da… <tibble> 1.84e-3 -0.00893  1.05 0.171     0.916 #> # … with 38 more rows, 9 more variables: df <dbl>, logLik <dbl>, AIC <dbl>, #> #   BIC <dbl>, deviance <dbl>, df.residual <int>, nobs <int>, #> #   lm_warnings <list>, lm_messages <list>, and abbreviated variable names #> #   ¹​specifications, ²​r.squared, ³​adj.r.squared, ⁴​statistic"},{"path":"/index.html","id":"reveal","dir":"","previous_headings":"Unpacking a multiverse analysis","what":"Reveal","title":"Tools for Running Multiverse Style Analyses","text":"wrote wrappers around unnest() workflow. main function reveal(). Pass multiverse results tibble reveal() tell columns grab indicating column name .argument: want get straight tidied result can specify sub-list .argument: can also choose expand specification blueprint .unpack_specs = TRUE see decisions produced result:","code":"multiverse_results |> reveal(.what = lm_fitted) #> # A tibble: 48 × 7 #>    decision specifications   lm_code         lm_tidy  lm_gla…¹ lm_war…² lm_mes…³ #>    <chr>    <list>           <glue>          <list>   <list>   <list>   <list>   #>  1 1        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  2 2        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  3 3        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  4 4        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  5 5        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  6 6        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  7 7        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  8 8        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #>  9 9        <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #> 10 10       <tibble [1 × 3]> the_data |> fi… <tibble> <tibble> <tibble> <tibble> #> # … with 38 more rows, and abbreviated variable names ¹​lm_glance, ²​lm_warnings, #> #   ³​lm_messages multiverse_results |> reveal(.what = lm_fitted, .which = lm_tidy) #> # A tibble: 192 × 7 #>    decision specifications   term         estimate std.error statistic p.value #>    <chr>    <list>           <chr>           <dbl>     <dbl>     <dbl>   <dbl> #>  1 1        <tibble [1 × 3]> (Intercept)  0.0117      0.0642    0.181    0.856 #>  2 1        <tibble [1 × 3]> iv1          0.000687    0.0668    0.0103   0.992 #>  3 1        <tibble [1 × 3]> mod          0.00133     0.0637    0.0209   0.983 #>  4 1        <tibble [1 × 3]> iv1:mod      0.0448      0.0675    0.664    0.507 #>  5 2        <tibble [1 × 3]> (Intercept) -0.0444      0.0637   -0.696    0.487 #>  6 2        <tibble [1 × 3]> iv1          0.00674     0.0663    0.102    0.919 #>  7 2        <tibble [1 × 3]> mod         -0.0154      0.0632   -0.244    0.807 #>  8 2        <tibble [1 × 3]> iv1:mod      0.0170      0.0670    0.255    0.799 #>  9 3        <tibble [1 × 3]> (Intercept)  0.0224      0.0633    0.354    0.724 #> 10 3        <tibble [1 × 3]> iv2          0.0176      0.0654    0.269    0.788 #> # … with 182 more rows multiverse_results |>    reveal(.what = lm_fitted, .which = lm_tidy, .unpack_specs = TRUE) #> # A tibble: 192 × 12 #>    decision ivs   dvs   include1    inclu…¹ inclu…² model term  estimate std.e…³ #>    <chr>    <chr> <chr> <chr>       <chr>   <chr>   <chr> <chr>    <dbl>   <dbl> #>  1 1        iv1   dv1   include1 =… includ… scale(… lm(d… (Int…  1.17e-2  0.0642 #>  2 1        iv1   dv1   include1 =… includ… scale(… lm(d… iv1    6.87e-4  0.0668 #>  3 1        iv1   dv1   include1 =… includ… scale(… lm(d… mod    1.33e-3  0.0637 #>  4 1        iv1   dv1   include1 =… includ… scale(… lm(d… iv1:…  4.48e-2  0.0675 #>  5 2        iv1   dv2   include1 =… includ… scale(… lm(d… (Int… -4.44e-2  0.0637 #>  6 2        iv1   dv2   include1 =… includ… scale(… lm(d… iv1    6.74e-3  0.0663 #>  7 2        iv1   dv2   include1 =… includ… scale(… lm(d… mod   -1.54e-2  0.0632 #>  8 2        iv1   dv2   include1 =… includ… scale(… lm(d… iv1:…  1.70e-2  0.0670 #>  9 3        iv2   dv1   include1 =… includ… scale(… lm(d… (Int…  2.24e-2  0.0633 #> 10 3        iv2   dv1   include1 =… includ… scale(… lm(d… iv2    1.76e-2  0.0654 #> # … with 182 more rows, 2 more variables: statistic <dbl>, p.value <dbl>, and #> #   abbreviated variable names ¹​include2, ²​include3, ³​std.error"},{"path":"/index.html","id":"condense","dir":"","previous_headings":"Unpacking a multiverse analysis","what":"Condense","title":"Tools for Running Multiverse Style Analyses","text":"Unpacking specifications alongside specific results allows us examine effects pipeline decisions. powerful way organize results condense specific results column, say predictor regression coefficient, entire multiverse. condense() takes result column summarizes .argument, takes list form list(<name pick> = <summary function>). .create column named like <column condsensed>_<summary function name provided>\". case, estimate_mean estimate_median. , filtered multiverse results look predictors iv* see mean median effect (combinations decisions) outcomes. However, three versions predictor two outcomes, combining dplyr::group_by() condense() might informative: interested terms model, can leverage group_by :","code":"multiverse_results |>    reveal(.what = lm_fitted, .which = lm_tidy, .unpack_specs = TRUE) |>    filter(str_detect(term, \"iv\")) |>    condense(estimate, list(mean = mean, median = median)) #> # A tibble: 1 × 2 #>   estimate_mean estimate_median #>           <dbl>           <dbl> #> 1     -0.000738         0.00872 multiverse_results |>    reveal(.what = lm_fitted, .which = lm_tidy, .unpack_specs = TRUE) |>    filter(str_detect(term, \"iv\")) |>   group_by(ivs, dvs) |>    condense(estimate, list(mean = mean, median = median)) #> # A tibble: 6 × 4 #> # Groups:   ivs [3] #>   ivs   dvs   estimate_mean estimate_median #>   <chr> <chr>         <dbl>           <dbl> #> 1 iv1   dv1         0.0268          0.0174  #> 2 iv1   dv2         0.00558         0.00846 #> 3 iv2   dv1        -0.0583         -0.0697  #> 4 iv2   dv2         0.00365         0.00650 #> 5 iv3   dv1         0.00886         0.00812 #> 6 iv3   dv2         0.00901         0.00748 multiverse_results |>    reveal(.what = lm_fitted, .which = lm_tidy, .unpack_specs = TRUE) |>    group_by(term, ivs, dvs) |>    condense(estimate, list(mean = mean, median = median)) #> # A tibble: 24 × 5 #> # Groups:   term, ivs [12] #>    term        ivs   dvs   estimate_mean estimate_median #>    <chr>       <chr> <chr>         <dbl>           <dbl> #>  1 (Intercept) iv1   dv1        -0.00112       -0.00111  #>  2 (Intercept) iv1   dv2         0.00997        0.0148   #>  3 (Intercept) iv2   dv1         0.00675        0.00692  #>  4 (Intercept) iv2   dv2         0.00885        0.0135   #>  5 (Intercept) iv3   dv1         0.00695        0.00657  #>  6 (Intercept) iv3   dv2         0.0102         0.0147   #>  7 iv1         iv1   dv1         0.0120         0.0117   #>  8 iv1         iv1   dv2         0.00958        0.00846  #>  9 iv1:mod     iv1   dv1         0.0416         0.0382   #> 10 iv1:mod     iv1   dv2         0.00159        0.000963 #> # … with 14 more rows"},{"path":"/index.html","id":"learning-more","dir":"","previous_headings":"","what":"Learning more","title":"Tools for Running Multiverse Style Analyses","text":"many features multitool, including pre-processing steps /post-processing blueprint. can also conduct multiverse-style descriptive analyses measurement analyses.","code":""},{"path":"/index.html","id":"other-related-packages","dir":"","previous_headings":"","what":"Other related packages","title":"Tools for Running Multiverse Style Analyses","text":"specr multiverse mverse","code":""},{"path":"/reference/add_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Add correlations from the correlation package in easystats — add_correlations","title":"Add correlations from the correlation package in easystats — add_correlations","text":"Add correlations correlation package easystats","code":""},{"path":"/reference/add_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add correlations from the correlation package in easystats — add_correlations","text":"","code":"add_correlations(   .df,   var_set,   variables,   focus_set = NULL,   method = \"auto\",   redundant = TRUE,   add_matrix = TRUE )"},{"path":"/reference/add_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add correlations from the correlation package in easystats — add_correlations","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_set character string. descriptive name correlation matrix. variables variables like correlations. variables passed link[correlation]{correlation}. can also use tidyselect select variables. focus_set variables focus one table. produces table rows focused variables columns variables method valid method correlation supplied link[correlation]{correlation} (e.g., 'pearson' 'kendall'). Defaults 'auto'. See link[correlation]{correlation} details. redundant logical, result include repeated correlations? Defaults TRUE See link[correlation]{correlation} details. add_matrix logical, add traditional correlation matrix output. Defaults TRUE.","code":""},{"path":"/reference/add_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add correlations from the correlation package in easystats — add_correlations","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_correlations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add correlations from the correlation package in easystats — add_correlations","text":"","code":"library(tidyverse) #> ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── #> ✔ ggplot2 3.4.0      ✔ purrr   1.0.1  #> ✔ tibble  3.1.8      ✔ dplyr   1.0.10 #> ✔ tidyr   1.2.1      ✔ stringr 1.5.0  #> ✔ readr   2.1.3      ✔ forcats 0.5.2  #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_cron_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"Add Cronbach's Alpha multiverse pipeline","code":""},{"path":"/reference/add_cron_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"","code":"add_cron_alpha(.df, scale_name, items, keys = NULL)"},{"path":"/reference/add_cron_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. scale_name character string. Indicates name scale measure measured items indicators items. items items (variables) comprise scale measure. variables passed link[psych]{alpha}. can also use tidyselect select variables. keys optional numeric vector indicating score items. 1 keyed normal directino -1 reverse scored. length keys must items.","code":""},{"path":"/reference/add_cron_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_cron_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"Add filtering/exclusion criteria multiverse pipeline","code":""},{"path":"/reference/add_filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"","code":"add_filters(.df, ...)"},{"path":"/reference/add_filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. ... logical expressions used filter separated commas. Expressions quoted.","code":""},{"path":"/reference/add_filters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"","code":"library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a model and formula to a multiverese pipeline — add_model","title":"Add a model and formula to a multiverese pipeline — add_model","text":"Add model formula multiverese pipeline","code":""},{"path":"/reference/add_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a model and formula to a multiverese pipeline — add_model","text":"","code":"add_model(.df, code)"},{"path":"/reference/add_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a model and formula to a multiverese pipeline — add_model","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. code literal model syntax like run. can use glue inside formulas dynamically generate variable names based variable grid. example, make variable grid two versions IVs (e.g., iv1 iv2), can write formula like : lm(happiness ~ {iv} + control_var). requirement variables written formula actually exist underlying data. also responsible loading packages run particular model (e.g., lme4 mixed-models)","code":""},{"path":"/reference/add_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a model and formula to a multiverese pipeline — add_model","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a model and formula to a multiverese pipeline — add_model","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_model(lm({dvs} ~ {ivs} * {mods})) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_postprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"Add arbitrary postprocessing code multiverse pipeline","code":""},{"path":"/reference/add_postprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"","code":"add_postprocess(.df, postprocess_name, code)"},{"path":"/reference/add_postprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. postprocess_name character string. descriptive name postprocessing step accomplishes. code literal code like execute analysis. code written work pipes (.e., |> %>%). post-processing code comes last multiverse analysis step, chosen model object passed post-processing code. example, fit simple linear model like: lm(y ~ x1 + x2), post-processing code executes call anova, simply pass anova() add_postprocess(). underlying code : data |> filters |> lm(y ~ x1 + x2, data = _) |> anova()","code":""},{"path":"/reference/add_postprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_postprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_model(lm({dvs} ~ {ivs} * {mods})) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_preprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"Add arbitrary preprocessing code multiverse analysis pipeline","code":""},{"path":"/reference/add_preprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"","code":"add_preprocess(.df, process_name, code)"},{"path":"/reference/add_preprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. process_name character string. descriptive name preprocessing step accomplishes. code literal code like execute data filtered. glue syntax allowed. example might centering scaling predictor appropriate filters applied data. code written work pipes (.e., |> %>%). Pre-processing code eventually take base data along filters applied data. means mutate calls natural functions take data.frame first argument work well (long also return data.frame).","code":""},{"path":"/reference/add_preprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_preprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"Add set descriptiove statistics compute set variables","code":""},{"path":"/reference/add_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"","code":"add_summary_stats(.df, var_set, variables, stats)"},{"path":"/reference/add_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_set character string. name set summary statistics variables variables like compute summary statistics. can also use tidyselect select variables. stats character vector stat names (e.g., c(\"mean\",\"sd\")). responsible loading packages compute preferred summary statistics. Summary statistic functions must work inside summarize.","code":""},{"path":"/reference/add_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/add_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a set of variable alternatives to a multiverse pipeline — add_variables","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"Add set variable alternatives multiverse pipeline","code":""},{"path":"/reference/add_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"","code":"add_variables(.df, var_group, ...)"},{"path":"/reference/add_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_group character string. Indicates name current set. example, \"primary_iv\" indicate set alternatives main predictor analysis. ... bare unquoted names variables include alternative options variable set. can also use tidyselect select variables.","code":""},{"path":"/reference/add_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"/reference/add_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"","code":"library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>  add_variables(\"ivs\", iv1, iv2, iv3) |>  add_variables(\"dvs\", dv1, dv2) |>  add_variables(\"mods\", starts_with(\"mod\")) #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found"},{"path":"/reference/condense.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize multiverse parameters — condense","title":"Summarize multiverse parameters — condense","text":"Summarize multiverse parameters","code":""},{"path":"/reference/condense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize multiverse parameters — condense","text":"","code":"condense(.unpacked, .what, .how)"},{"path":"/reference/condense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize multiverse parameters — condense","text":".unpacked unpacked (reveal unnest) multiverse dataset. .specific column summarize. model estimate, summary statistic, correlation, estimate computed multiverse. .named list. list contain summary functions (e.g., mean median) user like compute individual estimates multiverse","code":""},{"path":"/reference/condense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize multiverse parameters — condense","text":"summarized tibble containing column summary method .","code":""},{"path":"/reference/condense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize multiverse parameters — condense","text":"","code":"if (FALSE) {  library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal results of the linear model the_multiverse |> reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE)  # Reveal and condense the_multiverse |>   reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE) |>   group_by(term, dvs) |>   condense(estimate, list(mn = mean, med = median))   }"},{"path":"/reference/expand_decisions.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"Expand set multiverse decisions possible combinations","code":""},{"path":"/reference/expand_decisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"","code":"expand_decisions(.grid)"},{"path":"/reference/expand_decisions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":".grid ddata.frame produced calling series add_* functions.","code":""},{"path":"/reference/expand_decisions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"nested data.frame containing combinations arbitrary decisions multiverse analysis. Decision types become list columns matching type decisions called along pipeline (e.g., filters, variables, etc.). decisions containing glue syntax populated relevant information.","code":""},{"path":"/reference/expand_decisions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions() #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found  full_pipeline #> Error in eval(expr, envir, enclos): object 'full_pipeline' not found"},{"path":"/reference/icar_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Early Life Adversity and Cognitive Ability — icar_data","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"unpublished experiment looking effect priming economic threat childhood adversity International Cognitive Ability Resource (ICAR) scores","code":""},{"path":"/reference/icar_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"","code":"icar_data"},{"path":"/reference/icar_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"data frame 413 rows 63 variables: sample Lab online subsample condition Experimental condition, 0 = control (computer crash); 1 = experimental (recession) dems_gender gender identify ? dems_age AGE years? (e.g. 25) dems_ethnicity ethnicity? dems_edu highest level education completed? dems_us_born grow United States? dems_english_native grow speaking English? dems_fluency fluent English language? dems_lang English language know best? child_unp_obj1 many times parents legal guardians change jobs occupational status? child_unp_obj2 many times move change residence (move different house, neighborhood, city, state)? child_unp_obj3 many times changes familial circumstances? (divorce, parents starting new relationships, parents leaving home) child_unp_changes1 Economic status: child_unp_changes2 Family environment: child_unp_changes3 childhood neighborhood environment: child_unp_changes4 childhood school environment: child_unp_subj1 family life generally inconsistent unpredictable day--day. child_unp_subj2 parent(s) frequently arguments fights people childhood. child_unp_subj3 parents difficult divorce separation time. child_unp_subj4 People often moved house pretty random basis. child_unp_subj5 woke , often know happen house day. child_unp_subj6 family environment often tense \"edge\". child_unp_subj7 Things often chaotic house. child_unp_subj8 hard time knowing parent(s) people house going say. child_ses_subj1 grew relatively wealthy neighborhood. child_ses_subj2 felt relatively wealthy compared kids. child_ses_subj3 family usually enough money things growing . child_income household income growing ? unp_obj_mean Childhood unpredictability (objective) mean score unp_changes_mean Childhood unpredictability (changes) mean score unp_subj_mean Childhood unpredictability (subjective) mean score ses_subj_mean Childhood socioeconomic status (objective) mean score vr_04 Verbal reasoning item 4 vr_17 Verbal reasoning item 17 ln_07 Letter-number item 7 ln_58 Letter-number item 58 mx_45 Matrix reasoning item 45 mx_46 Matrix reasoning item 46 r3d_06 Mental Rotation item 6 r3d_08 Mental Rotation item 8 vr_16 Verbal reasoning item 16 vr_19 Verbal reasoning item 19 ln_33 Letter-number item 33 ln_34 Letter-number item 34 mx_47 Matrix reasoning item 47 mx_55 Matrix reasoning item 55 r3d_03 Mental Rotation item 3 r3d_04 Mental Rotation item 4 ln_sum Total score (4) letter-number items mx_sum Total score (4) matrix reasoning items vr_sum Total score (4) verbal reasoning items r3d_sum Total score (4) 3d rotation items icar_sum Total score (16) ICAR battery time_condition Time seconds experimental manipulation displayed (60 seconds) time_icar Time seconds took complete whole ICAR battery time_ln Time seconds took complete lettter-number items time_mx Time seconds took complete matrix reasoning items time_vr Time seconds took complete verbal reasoning items time_r3d Time seconds took complete 3d rotation items att_interrupt ever interrupted anyone anything time spent survey? att_one_sitting complete survey one sitting? att_getup ever get leave computer study (reason)?","code":""},{"path":"/reference/icar_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"data_URL","code":""},{"path":"/reference/icar_data_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data frame contains information documentation ICAR dataset provides use session.","code":""},{"path":"/reference/icar_data_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"","code":"icar_data_codebook"},{"path":"/reference/icar_data_codebook.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data frame 63 rows 3 variables: var_name name variable data var_label brief description variable var_values explanation values labels applicable","code":""},{"path":"/reference/icar_data_codebook.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data_URL","code":""},{"path":"/reference/report_universe_console.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a 'universe' console report — report_universe_console","title":"Create a 'universe' console report — report_universe_console","text":"Create 'universe' console report","code":""},{"path":"/reference/report_universe_console.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a 'universe' console report — report_universe_console","text":"","code":"report_universe_console(multiverse, decision_num)"},{"path":"/reference/report_universe_console.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a 'universe' console report — report_universe_console","text":"multiverse tibble created run_multiverse decision_num decision set create report ","code":""},{"path":"/reference/report_universe_console.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a 'universe' console report — report_universe_console","text":"","code":"if (FALSE) { my_multi_results <- run_multiverse(my_grid, .df)  report_universe_console(my_multi_verse, .df, 1) }"},{"path":"/reference/reveal.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal the contents of a multiverse analysis — reveal","title":"Reveal the contents of a multiverse analysis — reveal","text":"Reveal contents multiverse analysis","code":""},{"path":"/reference/reveal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal the contents of a multiverse analysis — reveal","text":"","code":"reveal(.multi, .what, .which = NULL, .unpack_specs = FALSE)"},{"path":"/reference/reveal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal the contents of a multiverse analysis — reveal","text":".multi multiverse list-column tibble produced run_multiverse. .name list-column like unpack .sub-list columns like unpack .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"/reference/reveal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal the contents of a multiverse analysis — reveal","text":"unnested part multiverse requested. usually contains particular estimates statistics like analyze decision grid specified.","code":""},{"path":"/reference/reveal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal the contents of a multiverse analysis — reveal","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal results of the linear model the_multiverse |> reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE) }"},{"path":"/reference/reveal_alphas.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"Reveal set multiverse cronbach's alpha statistics","code":""},{"path":"/reference/reveal_alphas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"","code":"reveal_alphas(.multi, .which, .unpack_specs = FALSE)"},{"path":"/reference/reveal_alphas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":".multi multiverse list-column tibble produced run_multiverse. .specific name alphas .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"/reference/reveal_alphas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"unnested set correlations per decision multiverse.","code":""},{"path":"/reference/reveal_alphas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal multiverse reliability analyses the_multiverse |> reveal(cron_alphas_computed) }"},{"path":"/reference/reveal_corrs.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of multiverse correlations — reveal_corrs","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"Reveal set multiverse correlations","code":""},{"path":"/reference/reveal_corrs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"","code":"reveal_corrs(.multi, .which, .unpack_specs = FALSE)"},{"path":"/reference/reveal_corrs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of multiverse correlations — reveal_corrs","text":".multi multiverse list-column tibble produced run_multiverse. .specific name correlations requested .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"/reference/reveal_corrs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"unnested set correlations per decision multiverse.","code":""},{"path":"/reference/reveal_corrs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal correlations among predictor across decision set the_multiverse |> reveal_corrs(predictors_rs) }"},{"path":"/reference/reveal_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"Reveal set summary statistics multiverse analysis","code":""},{"path":"/reference/reveal_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"","code":"reveal_summary_stats(.multi, .which, .unpack_specs = FALSE)"},{"path":"/reference/reveal_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":".multi multiverse list-column tibble produced run_multiverse. .specific name summary statistics .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"/reference/reveal_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"unnested set summary statistics per decision multiverse.","code":""},{"path":"/reference/reveal_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal summary statistics the_multiverse |> reveal_summary_stats(iv_stats) }"},{"path":"/reference/run_multiverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a multiverse based on a complete decision grid — run_multiverse","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"Run multiverse based complete decision grid","code":""},{"path":"/reference/run_multiverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"","code":"run_multiverse(.grid, save_model = FALSE, ncores = 1)"},{"path":"/reference/run_multiverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":".grid tibble produced expand_decisions save_model logical, indicates whether save model object entirety. default FALSE model objects usually large hood, tidy glance used summarize useful model information. ncores numeric. number cores want use parallel processing.","code":""},{"path":"/reference/run_multiverse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"single tibble containing tidied results model post-processing tests/tasks. unique test (e.g., lm aov called lm), list column function name created tidy glance warnings messages printed fitting models. Internally, modeling post-processing functions checked see tidy glance methods available. , summary called instead.","code":""},{"path":"/reference/run_multiverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"","code":"if (FALSE) { run_multiverse(data, grid) }"},{"path":"/reference/run_universe_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a single set of arbitrary decisions and save the result — run_universe_model","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"Run single set arbitrary decisions save result","code":""},{"path":"/reference/run_universe_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"","code":"run_universe_model(.grid, decision_num, save_model = FALSE)"},{"path":"/reference/run_universe_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":".grid tibble produced expand_decisions decision_num single integer 1 nrow(grid) indicating specific decision set run save_model logical, indicates whether save model object entirety. default FALSE model objects usually large hood, tidy glance used summarize useful model information.","code":""},{"path":"/reference/run_universe_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"single row tibble containing decision, code ran, results, notes (e.g., warnings messages).","code":""},{"path":"/reference/run_universe_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"","code":"if (FALSE) { run_universe(.grid, .df, decision_num) }"},{"path":"/reference/run_universe_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute summary statistics for a single decision set — run_universe_summary_stats","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"Compute summary statistics single decision set","code":""},{"path":"/reference/run_universe_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"","code":"run_universe_summary_stats(.grid, decision_num)"},{"path":"/reference/run_universe_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":".grid data.frame resulting expand_decisions decision_num index particular decision set want run","code":""},{"path":"/reference/run_universe_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"single row data.frame list columns containing summary statistics specified .grid","code":""},{"path":"/reference/run_universe_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  summary_stats_grid <-   the_data |>     add_variables(\"ivs\", iv1, iv2, iv3) |>     add_variables(\"dvs\", dv1, dv2) |>     add_variables(\"mods\", starts_with(\"mod\")) |>     add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>     add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>     add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>     expand_decisions() #> Error in rlang::eval_tidy(rlang::parse_expr(data_chr)): object 'the_data' not found  run_universe_summary_stats(summary_stats_grid, decision_num  = 12) #> Error in run_universe_summary_stats(summary_stats_grid, decision_num = 12): object 'summary_stats_grid' not found"},{"path":"/reference/show_code_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Show multiverse data code pipelines — show_code_filter","title":"Show multiverse data code pipelines — show_code_filter","text":"show_code* function self-explanatory - indicate along multiverse pipeline extract code. goal functions create window multiverse decision set context/results allow user inspect specific decisions straight code produced .","code":""},{"path":"/reference/show_code_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show multiverse data code pipelines — show_code_filter","text":"","code":"show_code_filter(.grid, decision_num, copy = F)  show_code_preprocess(.grid, decision_num, copy = F)  show_code_model(.grid, decision_num, copy = F)  show_code_postprocess(.grid, decision_num, copy = F)  show_code_summary_stats(.grid, decision_num, copy = F)  show_code_corrs(.grid, decision_num, copy = F)  show_code_cron_alpha(.grid, decision_num, copy = F)"},{"path":"/reference/show_code_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show multiverse data code pipelines — show_code_filter","text":".grid full decision grid created expand_decisions decision_num numeric. Indicates 'universe' multiverse show underlying code. copy logical. Whether copy pipeline code clipboard using write_clip.","code":""},{"path":"/reference/show_code_filter.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Show multiverse data code pipelines — show_code_filter","text":"show_code_preprocess(): Show code preprocessing stage show_code_model(): Show code modeling stage show_code_postprocess(): Show code post-processing stage show_code_summary_stats(): Show code computing summary statistics show_code_corrs(): Show code computing correlations show_code_cron_alpha(): Show code computing correlations","code":""}]
