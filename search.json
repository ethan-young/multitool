[{"path":"https://ethan-young.github.io/multitool/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 multitool authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Defining an Analysis Pipeline Blueprint","text":"First things first. multitool leverages tidyverse package lets load :","code":"library(tidyverse) library(multitool)"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"setting-up-a-data-analysis-pipeline","dir":"Articles","previous_headings":"","what":"Setting up a data analysis pipeline","title":"Defining an Analysis Pipeline Blueprint","text":"Image data several predictor variables, moderators, covariates, dependent measures. want know predictors (ivs) interact moderators (mods) predict outcome (dvs). three versions predictor (supposedly) measure thing, albeit slightly different ways. addition, collected messy data real world (really let’s pretend), idea observations include might exclude (e.g., include1, include2, include3).","code":"the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"create-a-blueprint","dir":"Articles","previous_headings":"","what":"Create a blueprint","title":"Defining an Analysis Pipeline Blueprint","text":"Say don’t know much new exciting area research. want maximize knowledge also want systematic. One approach specify reasonable analysis pipeline. Something looks like following: valid alternative alternatives pipeline? example, using iv2 instead iv1 using two exclusion criteria instead three? sensible approach copy code , paste , edit different decisions. quickly become tedious. adds many lines code, many new objects, difficult keep track systematic way. Enter multitool. multitool, analysis pipeline can transformed specification blueprint exploring combinations sensible data decisions pipeline. designed leverage already written code (e.g., filter statement ) create possible combinations data analysis pipelines.","code":"# Filter out exclusions filtered_data <-    the_data |>    filter(     include1 == 0,           # --     include2 != 3,           # Exclusion criteria     as.numeric(scale(include3)) > -2.5   # --   )  # Model the data my_model <- lm(dv1 ~ iv1 * mod, data = filtered_data)  # Check the results my_results <- parameters::parameters(my_model)"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"filtering-specifications","dir":"Articles","previous_headings":"","what":"Filtering specifications","title":"Defining an Analysis Pipeline Blueprint","text":"example three exclusion criteria. don’t know important, example, based arbitrary ‘rules thumb’ (may may inherent wisdom) don’t know including/excluding cases valid, can generate combinations: output simple tibble (.e., data.frame) containing three columns. row possible filter: type column refers type blueprint specification (see types filters), group refers variable base data frame (case the_data) filter applies, code column contains code needed execute filter. filtering decisions (e.g., exclusion criteria), ‘nothing’ alternative always generated. example, perhaps observations belong subgroup, include1 == 1. may may good reason exclude cases (depends specific situation). imagine don’t know include . include1 == 1 added add_filters(), ‘nothing’ alternative include1 %% unique(include1) automatically generated can compare including versus excluding cases based criterion.","code":"the_data |>    add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) #> # A tibble: 6 × 3 #>   type    group    code                           #>   <chr>   <chr>    <chr>                          #> 1 filters include1 include1 == 0                  #> 2 filters include1 include1 %in% unique(include1) #> 3 filters include2 include2 != 3                  #> 4 filters include2 include2 %in% unique(include2) #> 5 filters include3 scale(include3) > -2.5         #> 6 filters include3 include3 %in% unique(include3)"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"adding-alternative-analysis-variables","dir":"Articles","previous_headings":"","what":"Adding alternative analysis variables","title":"Defining an Analysis Pipeline Blueprint","text":"multiverse-style analyses explore range exclusion criteria alternatives. However, sometimes alternative versions variable also included. social sciences, fairly common many measures roughly construct (.e., measured variable). example, happiness researcher might measure positive mood, life satisfaction, /single item measuring happiness (e.g., ‘happy feel?’). want explore output pipeline differing versions variable, can use add_variables(). output generates tibble add_filters(). row particular decision use particular variable pipeline. contrast filter, however, need tell add_variables() call set variables var_group argument. multitool knows variable name code column different alternative larger set. , var_group = \"ivs\" indicates iv1, iv2, iv3 different versions ivs. used “ivs” way indicating alternative versions main independent variable. can add many variable sets want. example, might also want analyze two versions outcome, dv1 dv2.","code":"the_data |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) #> # A tibble: 3 × 3 #>   type      group code  #>   <chr>     <chr> <chr> #> 1 variables ivs   iv1   #> 2 variables ivs   iv2   #> 3 variables ivs   iv3 the_data |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) #> # A tibble: 5 × 3 #>   type      group code  #>   <chr>     <chr> <chr> #> 1 variables ivs   iv1   #> 2 variables ivs   iv2   #> 3 variables ivs   iv3   #> 4 variables dvs   dv1   #> 5 variables dvs   dv2"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"building-up-the-blueprint","dir":"Articles","previous_headings":"","what":"Building up the blueprint","title":"Defining an Analysis Pipeline Blueprint","text":"can harness real power multitool piping specification statements. example, perhaps want explore exclusion criteria alternatives across different versions predictor outcome variables. can simply pipe new blueprint specifications like : Notice now specification blueprint exclusion alternatives variable alternatives.","code":"the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) #> # A tibble: 11 × 3 #>    type      group    code                           #>    <chr>     <chr>    <chr>                          #>  1 filters   include1 include1 == 0                  #>  2 filters   include1 include1 %in% unique(include1) #>  3 filters   include2 include2 != 3                  #>  4 filters   include2 include2 %in% unique(include2) #>  5 filters   include3 scale(include3) > -2.5         #>  6 filters   include3 include3 %in% unique(include3) #>  7 variables ivs      iv1                            #>  8 variables ivs      iv2                            #>  9 variables ivs      iv3                            #> 10 variables dvs      dv1                            #> 11 variables dvs      dv2"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"adding-a-model","dir":"Articles","previous_headings":"","what":"Adding a model","title":"Defining an Analysis Pipeline Blueprint","text":"whole point building specification blueprint eventually feed model examine results. can add model blueprint using add_model(). designed add_model() user can simply paste model function. example, call lm() can simply pasted add_model(). Make sure give model label model_desc argument. , model completely unquoted. also data argument. intentional; multitool tracking base dataset along way (don’t ). Note can still quote model formula, style. make sure add_variables() works properly, add_model() designed interpret glue::glue() syntax. example: allows multitool insert correct version variable specified add_variables() step. Make sure use embrace variable var_group argument add_variables(), example add_model(lm({dvs} ~ {ivs} * mod)). , {dvs} ivs tells multitool insert current version ivs dvs model.","code":"the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"linear model\", lm(dv1 ~ iv1 * mod)) #> # A tibble: 12 × 3 #>    type      group        code                           #>    <chr>     <chr>        <chr>                          #>  1 filters   include1     include1 == 0                  #>  2 filters   include1     include1 %in% unique(include1) #>  3 filters   include2     include2 != 3                  #>  4 filters   include2     include2 %in% unique(include2) #>  5 filters   include3     scale(include3) > -2.5         #>  6 filters   include3     include3 %in% unique(include3) #>  7 variables ivs          iv1                            #>  8 variables ivs          iv2                            #>  9 variables ivs          iv3                            #> 10 variables dvs          dv1                            #> 11 variables dvs          dv2                            #> 12 models    linear model lm(dv1 ~ iv1 * mod) the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"linear model\", \"lm(dv1 ~ iv1 * mod)\") #> # A tibble: 12 × 3 #>    type      group        code                           #>    <chr>     <chr>        <chr>                          #>  1 filters   include1     include1 == 0                  #>  2 filters   include1     include1 %in% unique(include1) #>  3 filters   include2     include2 != 3                  #>  4 filters   include2     include2 %in% unique(include2) #>  5 filters   include3     scale(include3) > -2.5         #>  6 filters   include3     include3 %in% unique(include3) #>  7 variables ivs          iv1                            #>  8 variables ivs          iv2                            #>  9 variables ivs          iv3                            #> 10 variables dvs          dv1                            #> 11 variables dvs          dv2                            #> 12 models    linear model lm(dv1 ~ iv1 * mod) the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"linear model\", lm({dvs} ~ {ivs} * mod)) # see the {} here #> # A tibble: 12 × 3 #>    type      group        code                           #>    <chr>     <chr>        <chr>                          #>  1 filters   include1     include1 == 0                  #>  2 filters   include1     include1 %in% unique(include1) #>  3 filters   include2     include2 != 3                  #>  4 filters   include2     include2 %in% unique(include2) #>  5 filters   include3     scale(include3) > -2.5         #>  6 filters   include3     include3 %in% unique(include3) #>  7 variables ivs          iv1                            #>  8 variables ivs          iv2                            #>  9 variables ivs          iv3                            #> 10 variables dvs          dv1                            #> 11 variables dvs          dv2                            #> 12 models    linear model lm({dvs} ~ {ivs} * mod)"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"finalizing-the-specification-blueprint","dir":"Articles","previous_headings":"","what":"Finalizing the specification blueprint","title":"Defining an Analysis Pipeline Blueprint","text":"two steps finalizing bluerprint. first visualize pipeline graph. optional, think helpful. can automate making chart create_blueprint_graph(). Feed pipeline create_blueprint_graph() see chart multiverse pipeline plan: final step making blueprint expanding specifications possible combinations. can calling expand_decisions() end blueprint pipeline: result expanded tibble 1 row per unique decision columns major blueprint category. example, alternative variables (predictors outcomes), filters (three exclusion alternatives), model run. Note 3 exclusions (two combinations), 3 versions predictor, 2 versions outcome. means blueprint 2*2*2*3*2 r22232` rows, corresponds expanded pipeline: blueprint uses list columns organize information. can view list column using tidyr::unnest(<column name>). example, can look filters: look models: Notice , glue::glue() syntax, different versions predictors outcomes inserted appropriately. can check correspondence using unnest() models variable list columns:","code":"full_pipeline <-    the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  create_blueprint_graph(full_pipeline, width = 450, height = 500) #> no descriptives #> you have no preprocessing steps in your pipeline #> you have no post processing steps in your pipeline expanded_pipeline <- expand_decisions(full_pipeline)  expanded_pipeline #> # A tibble: 48 × 4 #>    decision variables        filters          models           #>    <chr>    <list>           <list>           <list>           #>  1 1        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  2 2        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  3 3        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  4 4        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  5 5        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  6 6        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  7 7        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  8 8        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  9 9        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #> 10 10       <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #> # ℹ 38 more rows 2*2*2*3*2 == nrow(expanded_pipeline) #> [1] TRUE expanded_pipeline |> unnest(filters) #> # A tibble: 48 × 6 #>    decision variables        include1      include2      include3       models   #>    <chr>    <list>           <chr>         <chr>         <chr>          <list>   #>  1 1        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  2 2        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  3 3        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  4 4        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  5 5        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  6 6        <tibble [1 × 2]> include1 == 0 include2 != 3 scale(include… <tibble> #>  7 7        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #>  8 8        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #>  9 9        <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #> 10 10       <tibble [1 × 2]> include1 == 0 include2 != 3 include3 %in%… <tibble> #> # ℹ 38 more rows expanded_pipeline |> unnest(models) #> # A tibble: 48 × 5 #>    decision variables        filters          model               model_meta   #>    <chr>    <list>           <list>           <chr>               <chr>        #>  1 1        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) linear model #>  2 2        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) linear model #>  3 3        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) linear model #>  4 4        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) linear model #>  5 5        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv3 * mod) linear model #>  6 6        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv3 * mod) linear model #>  7 7        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) linear model #>  8 8        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) linear model #>  9 9        <tibble [1 × 2]> <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) linear model #> 10 10       <tibble [1 × 2]> <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) linear model #> # ℹ 38 more rows expanded_pipeline |> unnest(c(variables, models)) #> # A tibble: 48 × 6 #>    decision ivs   dvs   filters          model               model_meta   #>    <chr>    <chr> <chr> <list>           <chr>               <chr>        #>  1 1        iv1   dv1   <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) linear model #>  2 2        iv1   dv2   <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) linear model #>  3 3        iv2   dv1   <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) linear model #>  4 4        iv2   dv2   <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) linear model #>  5 5        iv3   dv1   <tibble [1 × 3]> lm(dv1 ~ iv3 * mod) linear model #>  6 6        iv3   dv2   <tibble [1 × 3]> lm(dv2 ~ iv3 * mod) linear model #>  7 7        iv1   dv1   <tibble [1 × 3]> lm(dv1 ~ iv1 * mod) linear model #>  8 8        iv1   dv2   <tibble [1 × 3]> lm(dv2 ~ iv1 * mod) linear model #>  9 9        iv2   dv1   <tibble [1 × 3]> lm(dv1 ~ iv2 * mod) linear model #> 10 10       iv2   dv2   <tibble [1 × 3]> lm(dv2 ~ iv2 * mod) linear model #> # ℹ 38 more rows"},{"path":"https://ethan-young.github.io/multitool/articles/create-your-blueprint.html","id":"going-further","dir":"Articles","previous_headings":"","what":"Going further","title":"Defining an Analysis Pipeline Blueprint","text":"example uses relatively simple pipeline steps. can also add sophisticated steps pipeline, preprocessing data, post-processing model results, calculating descriptive statistics alongside model.","code":""},{"path":"https://ethan-young.github.io/multitool/articles/run-your-pipeline.html","id":"unpacking-a-multiverse-analysis","dir":"Articles","previous_headings":"","what":"Unpacking a multiverse analysis","title":"Run your Pipeline","text":"two main ways unpack examine multitool results. first using tidyr::unnest() (similar unpacking specification blueprint earlier).","code":""},{"path":"https://ethan-young.github.io/multitool/articles/run-your-pipeline.html","id":"unnest","dir":"Articles","previous_headings":"Unpacking a multiverse analysis","what":"Unnest","title":"Run your Pipeline","text":"Inside model_fitted column, multitool gives us 4 columns using model function ran prefix. first column always full code pipeline produced results. example, lm_code. next results passed broom (tidy /glance methods exist). lm, lm_tidy lm_glance. Notice naming convention: <model function>_params <model function>_performance. lm_params (<model function>_params) column gives us main results lm() per decision. include terms, estimates, standard errors, p-values. lm_performance (<model function>_performance) column gives us model fit statistics (among things):","code":"multiverse_results |> unnest(model_fitted) #> # A tibble: 48 × 7 #>    decision specifications   lm_code       lm_params  lm_performance lm_warnings #>    <chr>    <list>           <glue>        <list>     <list>         <list>      #>  1 1        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  2 2        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  3 3        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  4 4        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  5 5        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  6 6        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  7 7        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  8 8        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  9 9        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #> 10 10       <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #> # ℹ 38 more rows #> # ℹ 1 more variable: lm_messages <list> multiverse_results |>    unnest(model_fitted) |>    unnest(lm_params) #> # A tibble: 192 × 15 #>    decision specifications   lm_code parameter coefficient     se    ci   ci_low #>    <chr>    <list>           <glue>  <chr>           <dbl>  <dbl> <dbl>    <dbl> #>  1 1        <tibble [1 × 4]> the_da… (Interce…    -0.115   0.0615  0.95 -0.236   #>  2 1        <tibble [1 × 4]> the_da… iv1           0.0290  0.0602  0.95 -0.0895  #>  3 1        <tibble [1 × 4]> the_da… mod           0.0557  0.0638  0.95 -0.0699  #>  4 1        <tibble [1 × 4]> the_da… iv1:mod       0.0703  0.0614  0.95 -0.0505  #>  5 2        <tibble [1 × 4]> the_da… (Interce…     0.114   0.0607  0.95 -0.00540 #>  6 2        <tibble [1 × 4]> the_da… iv1          -0.0420  0.0594  0.95 -0.159   #>  7 2        <tibble [1 × 4]> the_da… mod           0.00662 0.0630  0.95 -0.117   #>  8 2        <tibble [1 × 4]> the_da… iv1:mod       0.0698  0.0606  0.95 -0.0495  #>  9 3        <tibble [1 × 4]> the_da… (Interce…    -0.119   0.0629  0.95 -0.243   #> 10 3        <tibble [1 × 4]> the_da… iv2          -0.0234  0.0648  0.95 -0.151   #> # ℹ 182 more rows #> # ℹ 7 more variables: ci_high <dbl>, t <dbl>, df_error <int>, p <dbl>, #> #   lm_performance <list>, lm_warnings <list>, lm_messages <list> multiverse_results |>    unnest(model_fitted) |>   unnest(lm_performance) #> # A tibble: 48 × 13 #>    decision specifications   lm_code        lm_params    aic  aicc   bic      r2 #>    <chr>    <list>           <glue>         <list>     <dbl> <dbl> <dbl>   <dbl> #>  1 1        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  906.  906.  925. 0.00638 #>  2 2        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  898.  898.  917. 0.00744 #>  3 3        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  906.  907.  925. 0.00552 #>  4 4        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  900.  900.  918. 0.00236 #>  5 5        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  907.  907.  925. 0.00491 #>  6 6        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  900.  900.  919. 0.00103 #>  7 7        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  910.  911.  929. 0.00615 #>  8 8        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  906.  906.  925. 0.00655 #>  9 9        <tibble [1 × 4]> the_data |> f… <prmtrs_m>  911.  911.  929. 0.00519 #> 10 10       <tibble [1 × 4]> the_data |> f… <prmtrs_m>  908.  908.  926. 0.00181 #> # ℹ 38 more rows #> # ℹ 5 more variables: r2_adjusted <dbl>, rmse <dbl>, sigma <dbl>, #> #   lm_warnings <list>, lm_messages <list>"},{"path":"https://ethan-young.github.io/multitool/articles/run-your-pipeline.html","id":"reveal","dir":"Articles","previous_headings":"Unpacking a multiverse analysis","what":"Reveal","title":"Run your Pipeline","text":"wrote wrappers around unnest() workflow. main function reveal(). Pass multiverse results tibble reveal() tell columns grab indicating column name .argument: want get straight tidied result can specify sub-list .argument: can also choose expand specification blueprint .unpack_specs = TRUE see decisions produced result:","code":"multiverse_results |>    reveal(.what = model_fitted) #> # A tibble: 48 × 7 #>    decision specifications   lm_code       lm_params  lm_performance lm_warnings #>    <chr>    <list>           <glue>        <list>     <list>         <list>      #>  1 1        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  2 2        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  3 3        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  4 4        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  5 5        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  6 6        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  7 7        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  8 8        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #>  9 9        <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #> 10 10       <tibble [1 × 4]> the_data |> … <prmtrs_m> <prfrmnc_>     <tibble>    #> # ℹ 38 more rows #> # ℹ 1 more variable: lm_messages <list> multiverse_results |>    reveal(.what = model_fitted, .which = lm_params) #> # A tibble: 192 × 11 #>    decision specifications   parameter coefficient     se    ci   ci_low ci_high #>    <chr>    <list>           <chr>           <dbl>  <dbl> <dbl>    <dbl>   <dbl> #>  1 1        <tibble [1 × 4]> (Interce…    -0.115   0.0615  0.95 -0.236   0.00598 #>  2 1        <tibble [1 × 4]> iv1           0.0290  0.0602  0.95 -0.0895  0.147   #>  3 1        <tibble [1 × 4]> mod           0.0557  0.0638  0.95 -0.0699  0.181   #>  4 1        <tibble [1 × 4]> iv1:mod       0.0703  0.0614  0.95 -0.0505  0.191   #>  5 2        <tibble [1 × 4]> (Interce…     0.114   0.0607  0.95 -0.00540 0.234   #>  6 2        <tibble [1 × 4]> iv1          -0.0420  0.0594  0.95 -0.159   0.0750  #>  7 2        <tibble [1 × 4]> mod           0.00662 0.0630  0.95 -0.117   0.131   #>  8 2        <tibble [1 × 4]> iv1:mod       0.0698  0.0606  0.95 -0.0495  0.189   #>  9 3        <tibble [1 × 4]> (Interce…    -0.119   0.0629  0.95 -0.243   0.00506 #> 10 3        <tibble [1 × 4]> iv2          -0.0234  0.0648  0.95 -0.151   0.104   #> # ℹ 182 more rows #> # ℹ 3 more variables: t <dbl>, df_error <int>, p <dbl> multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) #> # A tibble: 192 × 18 #>    decision ivs   dvs   include1  include2 include3 model model_meta filter_code #>    <chr>    <chr> <chr> <chr>     <chr>    <chr>    <chr> <chr>      <glue>      #>  1 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  2 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  3 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  4 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  5 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  6 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  7 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  8 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  9 3        iv2   dv1   include1… include… include… lm(d… linear mo… the_data |… #> 10 3        iv2   dv1   include1… include… include… lm(d… linear mo… the_data |… #> # ℹ 182 more rows #> # ℹ 9 more variables: parameter <chr>, coefficient <dbl>, se <dbl>, ci <dbl>, #> #   ci_low <dbl>, ci_high <dbl>, t <dbl>, df_error <int>, p <dbl>"},{"path":"https://ethan-young.github.io/multitool/articles/run-your-pipeline.html","id":"condense","dir":"Articles","previous_headings":"Unpacking a multiverse analysis","what":"Condense","title":"Run your Pipeline","text":"Unpacking specifications alongside specific results allows us examine effects pipeline decisions. powerful way organize results condense specific results column, say predictor regression coefficient, entire multiverse. condense() takes result column summarizes .argument, takes list form list(<name pick> = <summary function>). .create column named like <column condsensed>_<summary function name provided>\". case, coefficient_mean coefficient_median. , filtered multiverse results look predictors iv* see mean median effect (combinations decisions) outcomes. However, three versions predictor two outcomes, combining dplyr::group_by() condense() might informative: interested terms model, can leverage group_by :","code":"multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) |>    filter(str_detect(parameter, \"iv\")) |>    condense(coefficient, list(mean = mean, median = median)) #> # A tibble: 1 × 2 #>   coefficient_mean coefficient_median #>              <dbl>              <dbl> #> 1           0.0277             0.0286 multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) |>    filter(str_detect(parameter, \"iv\")) |>   group_by(ivs, dvs) |>    condense(coefficient, list(mean = mean, median = median)) #> # A tibble: 6 × 4 #> # Groups:   ivs [3] #>   ivs   dvs   coefficient_mean coefficient_median #>   <chr> <chr>            <dbl>              <dbl> #> 1 iv1   dv1             0.0410             0.0436 #> 2 iv1   dv2             0.0233             0.0261 #> 3 iv2   dv1             0.0264             0.0210 #> 4 iv2   dv2             0.0197             0.0193 #> 5 iv3   dv1             0.0308             0.0262 #> 6 iv3   dv2             0.0248             0.0291 multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) |>    group_by(parameter, ivs, dvs) |>    condense(coefficient, list(mean = mean, median = median)) #> # A tibble: 24 × 5 #> # Groups:   parameter, ivs [12] #>    parameter   ivs   dvs   coefficient_mean coefficient_median #>    <chr>       <chr> <chr>            <dbl>              <dbl> #>  1 (Intercept) iv1   dv1            -0.0973            -0.0974 #>  2 (Intercept) iv1   dv2             0.100              0.0951 #>  3 (Intercept) iv2   dv1            -0.0998            -0.0999 #>  4 (Intercept) iv2   dv2             0.106              0.0997 #>  5 (Intercept) iv3   dv1            -0.0910            -0.0920 #>  6 (Intercept) iv3   dv2             0.103              0.0975 #>  7 iv1         iv1   dv1             0.0474             0.0445 #>  8 iv1         iv1   dv2            -0.0206            -0.0200 #>  9 iv1:mod     iv1   dv1             0.0345             0.0299 #> 10 iv1:mod     iv1   dv2             0.0673             0.0653 #> # ℹ 14 more rows"},{"path":"https://ethan-young.github.io/multitool/articles/validate-your-blueprint.html","id":"blueprint-metadata","dir":"Articles","previous_headings":"","what":"Blueprint metadata","title":"Check and Test your Blueprint","text":"detect_* functions printing metadata pipeline. several filtering decisions, can also print summary sample sizes exclusion criteria applied. satisfied pipeline metadata, can expand test . , expand full decision grid.","code":"# Number of unique analysis pipelines detect_multiverse_n(full_pipeline) #> [1] 48  # Number of different versions of analysis variables detect_n_filters(full_pipeline) #> [1] 8  # Number of unique filtering criteria detect_n_filters(full_pipeline) #> [1] 8  # Number of unique models detect_n_models(full_pipeline) #> [1] 1 summarize_filter_ns(full_pipeline) #> # A tibble: 6 × 4 #>   filter_expression              variable n_retained n_excluded #>   <chr>                          <chr>         <int>      <int> #> 1 include1 == 0                  include1        447         53 #> 2 include1 %in% unique(include1) include1        500          0 #> 3 include2 != 3                  include2        341        159 #> 4 include2 %in% unique(include2) include2        500          0 #> 5 include3 > -2.5                include3        494          6 #> 6 include3 %in% unique(include3) include3        500          0 expanded_pipeline <- expand_decisions(full_pipeline)"},{"path":"https://ethan-young.github.io/multitool/articles/validate-your-blueprint.html","id":"test-your-blueprint","dir":"Articles","previous_headings":"","what":"Test your blueprint","title":"Check and Test your Blueprint","text":"multitool specification blueprint special feature: captures code generates analysis pipelines. special set functions show_code_* prefix allow see code executed single pipeline. example, can look filtering code first decision blueprint: functions allow generate relevant code along analysis pipeline. example, can look model pipeline decision 17 using show_code_model(decision_num = 17): Setting copy argument TRUE allows send code straight clipboard. can paste source console testing/editing. can also run individual decisions test work.","code":"# Take a look at the first filter decision expanded_pipeline |> show_code_filter(decision_num = 1) #> the_data |>  #>   filter(include1 == 0, include2 != 3, include3 > -2.5) expanded_pipeline |> show_code_model(decision_num = 17) #> the_data |>  #>   filter(include1 == 0, include2 %in% unique(include2), include3 > -2.5) |>  #>   lm(dv1 ~ iv3 * mod, data = _) run_universe_model(expanded_pipeline, decision_num = 1) #> # A tibble: 1 × 3 #>   decision filter_code                                              model_fitted #>   <chr>    <glue>                                                   <list>       #> 1 1        the_data |> filter(include1 == 0, include2 != 3, includ… <tibble>"},{"path":"https://ethan-young.github.io/multitool/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ethan Young. Author, maintainer. Stefan Vermeent. Author.","code":""},{"path":"https://ethan-young.github.io/multitool/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Young E, Vermeent S (2023). multitool: Tools Running Multiverse Style Analyses. R package version 0.0.0.9000, https://ethan-young.github.io/multitool/.","code":"@Manual{,   title = {multitool: Tools for Running Multiverse Style Analyses},   author = {Ethan Young and Stefan Vermeent},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://ethan-young.github.io/multitool/}, }"},{"path":"https://ethan-young.github.io/multitool/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Running Multiverse Style Analyses","text":"can install development version multitool GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"ethan-young/multitool\")"},{"path":"https://ethan-young.github.io/multitool/index.html","id":"motivation","dir":"","previous_headings":"","what":"Motivation","title":"Tools for Running Multiverse Style Analyses","text":"goal multitool provide set tools designing running multiverse-style analyses. designed help users create incremental workflow slowly building , keeping track , unpacking multiverse analyses results.","code":""},{"path":"https://ethan-young.github.io/multitool/index.html","id":"multiverse-primer","dir":"","previous_headings":"","what":"Multiverse Primer","title":"Tools for Running Multiverse Style Analyses","text":"unfamiliar multiverse analysis, short primer:","code":""},{"path":"https://ethan-young.github.io/multitool/index.html","id":"beyond-multiverse","dir":"","previous_headings":"","what":"Beyond Multiverse","title":"Tools for Running Multiverse Style Analyses","text":"designed multitool multiverse analysis really just tool exploration. new field, area, project, lot uncertainty data analysis decisions make. Clear research questions criteria help reduce uncertainty answer never fully reduce . multitool helps organize systematically explore different options. ’s really .","code":""},{"path":"https://ethan-young.github.io/multitool/index.html","id":"design","dir":"","previous_headings":"","what":"Design","title":"Tools for Running Multiverse Style Analyses","text":"designed multitool help users take single use case (e.g., single analysis pipeline) expand workflow include alternative versions analysis. example, imagine like take data, remove outliers, transform variables, run linear model, post-hoc analysis, plot results. multitool can take theses tasks transform blueprint, provides instructions running analysis pipeline. functions designed play nice tidyverse require using base R pipe |>. makes easy quickly convert single analysis multiverse analysis.","code":""},{"path":"https://ethan-young.github.io/multitool/index.html","id":"basic-components","dir":"","previous_headings":"","what":"Basic components","title":"Tools for Running Multiverse Style Analyses","text":"vision multitool workflow contains five steps:  multitool make decisions – know set data decisions – can help create organize workflow . defining feature multitool saves code. allows user grab code produces result inspect accuracy, errors, simply peace mind. quickly grabbing code, user can iterate creating blueprint checking code works intended. multitool allows user model data however ’d like. user responsible loading relevant modeling packages. Regardless model choice, multitool capture code build blueprint alternative analysis pipelines. Finally, multiverse analyses originally intended look model parameters shift function arbitrary data decisions. However, computation might change depending slice dice data. reason, also built functions computing descriptive, correlation, reliability analysis alongside particular modelling pipeline.","code":""},{"path":"https://ethan-young.github.io/multitool/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Tools for Running Multiverse Style Analyses","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:100,     iv1 = rnorm(100),     iv2 = rnorm(100),     iv3 = rnorm(100),     mod = rnorm(100),     dv1 = rnorm(100),     dv2 = rnorm(100),     include1 = rbinom(100, size = 1, prob = .1),     include2 = sample(1:3, size = 100, replace = TRUE),     include3 = rnorm(100)   )  # create a pipeline blueprint full_pipeline <-    the_data |>   add_filters(include1 == 0, include2 != 3, include3 > -2.5) |>    add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>    add_variables(var_group = \"dvs\", dv1, dv2) |>    add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  full_pipeline #> # A tibble: 12 × 3 #>    type      group        code                           #>    <chr>     <chr>        <chr>                          #>  1 filters   include1     include1 == 0                  #>  2 filters   include1     include1 %in% unique(include1) #>  3 filters   include2     include2 != 3                  #>  4 filters   include2     include2 %in% unique(include2) #>  5 filters   include3     include3 > -2.5                #>  6 filters   include3     include3 %in% unique(include3) #>  7 variables ivs          iv1                            #>  8 variables ivs          iv2                            #>  9 variables ivs          iv3                            #> 10 variables dvs          dv1                            #> 11 variables dvs          dv2                            #> 12 models    linear model lm({dvs} ~ {ivs} * mod)  # Visualize the pipeline create_blueprint_graph(full_pipeline) # expand the pipeline expanded_pipeline <- expand_decisions(full_pipeline) expanded_pipeline #> # A tibble: 48 × 4 #>    decision variables        filters          models           #>    <chr>    <list>           <list>           <list>           #>  1 1        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  2 2        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  3 3        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  4 4        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  5 5        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  6 6        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  7 7        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  8 8        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #>  9 9        <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #> 10 10       <tibble [1 × 2]> <tibble [1 × 3]> <tibble [1 × 2]> #> # ℹ 38 more rows  # Use your blueprint to run the multiverse multiverse_results <- run_multiverse(expanded_pipeline) multiverse_results #> # A tibble: 48 × 3 #>    decision specifications   model_fitted     #>    <chr>    <list>           <list>           #>  1 1        <tibble [1 × 4]> <tibble [1 × 5]> #>  2 2        <tibble [1 × 4]> <tibble [1 × 5]> #>  3 3        <tibble [1 × 4]> <tibble [1 × 5]> #>  4 4        <tibble [1 × 4]> <tibble [1 × 5]> #>  5 5        <tibble [1 × 4]> <tibble [1 × 5]> #>  6 6        <tibble [1 × 4]> <tibble [1 × 5]> #>  7 7        <tibble [1 × 4]> <tibble [1 × 5]> #>  8 8        <tibble [1 × 4]> <tibble [1 × 5]> #>  9 9        <tibble [1 × 4]> <tibble [1 × 5]> #> 10 10       <tibble [1 × 4]> <tibble [1 × 5]> #> # ℹ 38 more rows  # Unpack some results multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) #> # A tibble: 192 × 18 #>    decision ivs   dvs   include1  include2 include3 model model_meta filter_code #>    <chr>    <chr> <chr> <chr>     <chr>    <chr>    <chr> <chr>      <glue>      #>  1 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  2 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  3 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  4 1        iv1   dv1   include1… include… include… lm(d… linear mo… the_data |… #>  5 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  6 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  7 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  8 2        iv1   dv2   include1… include… include… lm(d… linear mo… the_data |… #>  9 3        iv2   dv1   include1… include… include… lm(d… linear mo… the_data |… #> 10 3        iv2   dv1   include1… include… include… lm(d… linear mo… the_data |… #> # ℹ 182 more rows #> # ℹ 9 more variables: parameter <chr>, coefficient <dbl>, se <dbl>, ci <dbl>, #> #   ci_low <dbl>, ci_high <dbl>, t <dbl>, df_error <int>, p <dbl>  # Summarize an effect multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) |>    filter(str_detect(parameter, \"iv\")) |>    condense(coefficient, list(mean = mean, median = median)) #> # A tibble: 1 × 2 #>   coefficient_mean coefficient_median #>              <dbl>              <dbl> #> 1         -0.00802            -0.0319  # Plot your effects multiverse_results |>    reveal(.what = model_fitted, .which = lm_params, .unpack_specs = TRUE) |>    filter(str_detect(parameter, \"^iv\\\\d$\")) |>    group_by(ivs, dvs) |>    mutate(sorted_decision = fct_reorder(as_factor(decision), coefficient) |> as.numeric()) |>    ggplot(aes(x = sorted_decision, y = coefficient, color = ivs)) +   geom_line() +   geom_point() +   facet_wrap(~dvs, scales = \"free_x\") +   scale_x_continuous(\"Data Decision\")"},{"path":"https://ethan-young.github.io/multitool/reference/add_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Add correlations from the correlation package in easystats — add_correlations","title":"Add correlations from the correlation package in easystats — add_correlations","text":"Add correlations correlation package easystats","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add correlations from the correlation package in easystats — add_correlations","text":"","code":"add_correlations(   .df,   var_set,   variables,   focus_set = NULL,   method = \"auto\",   redundant = TRUE,   add_matrix = TRUE )"},{"path":"https://ethan-young.github.io/multitool/reference/add_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add correlations from the correlation package in easystats — add_correlations","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_set character string. descriptive name correlation matrix. variables variables like correlations. variables passed link[correlation]{correlation}. can also use tidyselect select variables. focus_set variables focus one table. produces table rows focused variables columns variables method valid method correlation supplied link[correlation]{correlation} (e.g., 'pearson' 'kendall'). Defaults 'auto'. See link[correlation]{correlation} details. redundant logical, result include repeated correlations? Defaults TRUE See link[correlation]{correlation} details. add_matrix logical, add traditional correlation matrix output. Defaults TRUE.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add correlations from the correlation package in easystats — add_correlations","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_correlations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add correlations from the correlation package in easystats — add_correlations","text":"","code":"library(tidyverse) #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.2     ✔ readr     2.1.4 #> ✔ forcats   1.0.0     ✔ stringr   1.5.0 #> ✔ ggplot2   3.4.3     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0 #> ✔ purrr     1.0.2      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) #> # A tibble: 18 × 3 #>    type      group             code                                              #>    <chr>     <chr>             <chr>                                             #>  1 filters   include1          \"include1 == 0\"                                   #>  2 filters   include1          \"include1 %in% unique(include1)\"                  #>  3 filters   include2          \"include2 != 3\"                                   #>  4 filters   include2          \"include2 != 2\"                                   #>  5 filters   include2          \"include2 %in% unique(include2)\"                  #>  6 filters   include3          \"scale(include3) > -2.5\"                          #>  7 filters   include3          \"include3 %in% unique(include3)\"                  #>  8 variables ivs               \"iv1\"                                             #>  9 variables ivs               \"iv2\"                                             #> 10 variables ivs               \"iv3\"                                             #> 11 variables dvs               \"dv1\"                                             #> 12 variables dvs               \"dv2\"                                             #> 13 variables mods              \"mod1\"                                            #> 14 variables mods              \"mod2\"                                            #> 15 variables mods              \"mod3\"                                            #> 16 corrs     predictors_rs     \"select(matches(\\\"iv|mod|cov\\\")) |> correlation(… #> 17 corrs     predictors_matrix \"select(matches(\\\"iv|mod|cov\\\")) |> correlation(… #> 18 corrs     predictors_focus  \"select(matches(\\\"iv|mod|cov\\\")) |> correlation(…"},{"path":"https://ethan-young.github.io/multitool/reference/add_cron_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"Add Cronbach's Alpha multiverse pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_cron_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"","code":"add_cron_alpha(.df, scale_name, items, keys = NULL)"},{"path":"https://ethan-young.github.io/multitool/reference/add_cron_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. scale_name character string. Indicates name scale measure measured items indicators items. items items (variables) comprise scale measure. variables passed link[psych]{alpha}. can also use tidyselect select variables. keys optional numeric vector indicating score items. 1 keyed normal directino -1 reverse scored. length keys must items.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_cron_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_cron_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Cronbach's Alpha to a multiverse pipeline — add_cron_alpha","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) #> # A tibble: 16 × 3 #>    type        group     code                                #>    <chr>       <chr>     <chr>                               #>  1 filters     include1  include1 == 0                       #>  2 filters     include1  include1 %in% unique(include1)      #>  3 filters     include2  include2 != 3                       #>  4 filters     include2  include2 != 2                       #>  5 filters     include2  include2 %in% unique(include2)      #>  6 filters     include3  scale(include3) > -2.5              #>  7 filters     include3  include3 %in% unique(include3)      #>  8 variables   ivs       iv1                                 #>  9 variables   ivs       iv2                                 #> 10 variables   ivs       iv3                                 #> 11 variables   dvs       dv1                                 #> 12 variables   dvs       dv2                                 #> 13 variables   mods      mod1                                #> 14 variables   mods      mod2                                #> 15 variables   mods      mod3                                #> 16 cron_alphas unp_scale select(c(iv1, iv2, iv3)) |> alpha()"},{"path":"https://ethan-young.github.io/multitool/reference/add_filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"Add filtering/exclusion criteria multiverse pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"","code":"add_filters(.df, ...)"},{"path":"https://ethan-young.github.io/multitool/reference/add_filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. ... logical expressions used filter separated commas. Expressions quoted.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_filters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add filtering/exclusion criteria to a multiverse pipeline — add_filters","text":"","code":"library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) #> # A tibble: 7 × 3 #>   type    group    code                           #>   <chr>   <chr>    <chr>                          #> 1 filters include1 include1 == 0                  #> 2 filters include1 include1 %in% unique(include1) #> 3 filters include2 include2 != 3                  #> 4 filters include2 include2 != 2                  #> 5 filters include2 include2 %in% unique(include2) #> 6 filters include3 scale(include3) > -2.5         #> 7 filters include3 include3 %in% unique(include3)"},{"path":"https://ethan-young.github.io/multitool/reference/add_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a model and formula to a multiverese pipeline — add_model","title":"Add a model and formula to a multiverese pipeline — add_model","text":"Add model formula multiverese pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a model and formula to a multiverese pipeline — add_model","text":"","code":"add_model(.df, model_desc, code)"},{"path":"https://ethan-young.github.io/multitool/reference/add_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a model and formula to a multiverese pipeline — add_model","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. model_desc human readable name like give model. code literal model syntax like run. can use glue inside formulas dynamically generate variable names based variable grid. example, make variable grid two versions IVs (e.g., iv1 iv2), can write formula like : lm(happiness ~ {iv} + control_var). requirement variables written formula actually exist underlying data. also responsible loading packages run particular model (e.g., lme4 mixed-models)","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a model and formula to a multiverese pipeline — add_model","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a model and formula to a multiverese pipeline — add_model","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * {mods})) #> # A tibble: 17 × 3 #>    type       group        code                           #>    <chr>      <chr>        <chr>                          #>  1 filters    include1     include1 == 0                  #>  2 filters    include1     include1 %in% unique(include1) #>  3 filters    include2     include2 != 3                  #>  4 filters    include2     include2 != 2                  #>  5 filters    include2     include2 %in% unique(include2) #>  6 filters    include3     scale(include3) > -2.5         #>  7 filters    include3     include3 %in% unique(include3) #>  8 variables  ivs          iv1                            #>  9 variables  ivs          iv2                            #> 10 variables  ivs          iv3                            #> 11 variables  dvs          dv1                            #> 12 variables  dvs          dv2                            #> 13 variables  mods         mod1                           #> 14 variables  mods         mod2                           #> 15 variables  mods         mod3                           #> 16 preprocess scale_iv     mutate({ivs} = scale({ivs}))   #> 17 models     linear model lm({dvs} ~ {ivs} * {mods})"},{"path":"https://ethan-young.github.io/multitool/reference/add_postprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"Add arbitrary postprocessing code multiverse pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_postprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"","code":"add_postprocess(.df, postprocess_name, code)"},{"path":"https://ethan-young.github.io/multitool/reference/add_postprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. postprocess_name character string. descriptive name postprocessing step accomplishes. code literal code like execute analysis. code written work pipes (.e., |> %>%). post-processing code comes last multiverse analysis step, chosen model object passed post-processing code. example, fit simple linear model like: lm(y ~ x1 + x2), post-processing code executes call anova, simply pass anova() add_postprocess(). underlying code : data |> filters |> lm(y ~ x1 + x2, data = _) |> anova()","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_postprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_postprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add arbitrary postprocessing code to a multiverse pipeline — add_postprocess","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * {mods})) |>   add_postprocess(\"analysis of variance\", aov()) #> # A tibble: 18 × 3 #>    type        group                code                           #>    <chr>       <chr>                <chr>                          #>  1 filters     include1             include1 == 0                  #>  2 filters     include1             include1 %in% unique(include1) #>  3 filters     include2             include2 != 3                  #>  4 filters     include2             include2 != 2                  #>  5 filters     include2             include2 %in% unique(include2) #>  6 filters     include3             scale(include3) > -2.5         #>  7 filters     include3             include3 %in% unique(include3) #>  8 variables   ivs                  iv1                            #>  9 variables   ivs                  iv2                            #> 10 variables   ivs                  iv3                            #> 11 variables   dvs                  dv1                            #> 12 variables   dvs                  dv2                            #> 13 variables   mods                 mod1                           #> 14 variables   mods                 mod2                           #> 15 variables   mods                 mod3                           #> 16 preprocess  scale_iv             mutate({ivs} = scale({ivs}))   #> 17 models      linear model         lm({dvs} ~ {ivs} * {mods})     #> 18 postprocess analysis of variance aov()"},{"path":"https://ethan-young.github.io/multitool/reference/add_preprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"Add arbitrary preprocessing code multiverse analysis pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_preprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"","code":"add_preprocess(.df, process_name, code)"},{"path":"https://ethan-young.github.io/multitool/reference/add_preprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. process_name character string. descriptive name preprocessing step accomplishes. code literal code like execute data filtered. glue syntax allowed. example might centering scaling predictor appropriate filters applied data. code written work pipes (.e., |> %>%). Pre-processing code eventually take base data along filters applied data. means mutate calls natural functions take data.frame first argument work well (long also return data.frame).","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_preprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_preprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add arbitrary preprocessing code to a multiverse analysis pipeline — add_preprocess","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(\"scale_iv\", 'mutate({ivs} = scale({ivs}))') #> # A tibble: 16 × 3 #>    type       group    code                           #>    <chr>      <chr>    <chr>                          #>  1 filters    include1 include1 == 0                  #>  2 filters    include1 include1 %in% unique(include1) #>  3 filters    include2 include2 != 3                  #>  4 filters    include2 include2 != 2                  #>  5 filters    include2 include2 %in% unique(include2) #>  6 filters    include3 scale(include3) > -2.5         #>  7 filters    include3 include3 %in% unique(include3) #>  8 variables  ivs      iv1                            #>  9 variables  ivs      iv2                            #> 10 variables  ivs      iv3                            #> 11 variables  dvs      dv1                            #> 12 variables  dvs      dv2                            #> 13 variables  mods     mod1                           #> 14 variables  mods     mod2                           #> 15 variables  mods     mod3                           #> 16 preprocess scale_iv mutate({ivs} = scale({ivs}))"},{"path":"https://ethan-young.github.io/multitool/reference/add_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"Add set descriptiove statistics compute set variables","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"","code":"add_summary_stats(.df, var_set, variables, stats)"},{"path":"https://ethan-young.github.io/multitool/reference/add_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_set character string. name set summary statistics variables variables like compute summary statistics. can also use tidyselect select variables. stats character vector stat names (e.g., c(\"mean\",\"sd\")). responsible loading packages compute preferred summary statistics. Summary statistic functions must work inside summarize.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a set of descriptiove statistics to compute over a set of variables — add_summary_stats","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) #> # A tibble: 19 × 3 #>    type          group     code                                                  #>    <chr>         <chr>     <chr>                                                 #>  1 filters       include1  \"include1 == 0\"                                       #>  2 filters       include1  \"include1 %in% unique(include1)\"                      #>  3 filters       include2  \"include2 != 3\"                                       #>  4 filters       include2  \"include2 != 2\"                                       #>  5 filters       include2  \"include2 %in% unique(include2)\"                      #>  6 filters       include3  \"scale(include3) > -2.5\"                              #>  7 filters       include3  \"include3 %in% unique(include3)\"                      #>  8 variables     ivs       \"iv1\"                                                 #>  9 variables     ivs       \"iv2\"                                                 #> 10 variables     ivs       \"iv3\"                                                 #> 11 variables     dvs       \"dv1\"                                                 #> 12 variables     dvs       \"dv2\"                                                 #> 13 variables     mods      \"mod1\"                                                #> 14 variables     mods      \"mod2\"                                                #> 15 variables     mods      \"mod3\"                                                #> 16 preprocess    scale_iv  \"mutate({ivs} = scale({ivs}))\"                        #> 17 preprocess    scale_mod \"mutate(`:=`({mods}, scale({mods})))\"                 #> 18 summary_stats iv_stats  \"select(c(starts_with(\\\"iv\\\"))) |> summarize(across(… #> 19 summary_stats dv_stats  \"select(c(starts_with(\\\"dv\\\"))) |> summarize(across(…"},{"path":"https://ethan-young.github.io/multitool/reference/add_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a set of variable alternatives to a multiverse pipeline — add_variables","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"Add set variable alternatives multiverse pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"","code":"add_variables(.df, var_group, ...)"},{"path":"https://ethan-young.github.io/multitool/reference/add_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":".df original data.frame (e.g., base data set). part set add_* decision functions pipeline, base data passed along attribute. var_group character string. Indicates name current set. example, \"primary_iv\" indicate set alternatives main predictor analysis. ... bare unquoted names variables include alternative options variable set. can also use tidyselect select variables.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"data.frame three columns: type, group, code. Type indicates decision type, group decision, code actual code executed. part pipe, current set decisions appended new rows.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/add_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a set of variable alternatives to a multiverse pipeline — add_variables","text":"","code":"library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  the_data |>  add_variables(\"ivs\", iv1, iv2, iv3) |>  add_variables(\"dvs\", dv1, dv2) |>  add_variables(\"mods\", starts_with(\"mod\")) #> # A tibble: 8 × 3 #>   type      group code  #>   <chr>     <chr> <chr> #> 1 variables ivs   iv1   #> 2 variables ivs   iv2   #> 3 variables ivs   iv3   #> 4 variables dvs   dv1   #> 5 variables dvs   dv2   #> 6 variables mods  mod1  #> 7 variables mods  mod2  #> 8 variables mods  mod3"},{"path":"https://ethan-young.github.io/multitool/reference/condense.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize multiverse parameters — condense","title":"Summarize multiverse parameters — condense","text":"Summarize multiverse parameters","code":""},{"path":"https://ethan-young.github.io/multitool/reference/condense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize multiverse parameters — condense","text":"","code":"condense(.unpacked, .what, .how)"},{"path":"https://ethan-young.github.io/multitool/reference/condense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize multiverse parameters — condense","text":".unpacked unpacked (reveal unnest) multiverse dataset. .specific column summarize. model estimate, summary statistic, correlation, estimate computed multiverse. .named list. list contain summary functions (e.g., mean median) user like compute individual estimates multiverse","code":""},{"path":"https://ethan-young.github.io/multitool/reference/condense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize multiverse parameters — condense","text":"summarized tibble containing column summary method .","code":""},{"path":"https://ethan-young.github.io/multitool/reference/condense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize multiverse parameters — condense","text":"","code":"if (FALSE) {  library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal results of the linear model the_multiverse |> reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE)  # Reveal and condense the_multiverse |>   reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE) |>   group_by(term, dvs) |>   condense(estimate, list(mn = mean, med = median))   }"},{"path":"https://ethan-young.github.io/multitool/reference/create_blueprint_graph.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Analysis Pipeline diagram — create_blueprint_graph","title":"Create a Analysis Pipeline diagram — create_blueprint_graph","text":"Create Analysis Pipeline diagram","code":""},{"path":"https://ethan-young.github.io/multitool/reference/create_blueprint_graph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Analysis Pipeline diagram — create_blueprint_graph","text":"","code":"create_blueprint_graph(   .grid,   splines = \"line\",   render = TRUE,   show_code = FALSE,   ... )"},{"path":"https://ethan-young.github.io/multitool/reference/create_blueprint_graph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Analysis Pipeline diagram — create_blueprint_graph","text":".grid data.frame produced calling series add_* functions. splines options draw edges (lines) grViz diagram render whether render graph just output grViz code show_code whether show code generated diagram ... additional options passed DiagrammeR::grViz()","code":""},{"path":"https://ethan-young.github.io/multitool/reference/create_blueprint_graph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Analysis Pipeline diagram — create_blueprint_graph","text":"grViz graph pipeline","code":""},{"path":"https://ethan-young.github.io/multitool/reference/create_blueprint_graph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Analysis Pipeline diagram — create_blueprint_graph","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  create_blueprint_graph(full_pipeline) #> no descriptives #> you have no preprocessing steps in your pipeline #> you have no post processing steps in your pipeline  {\"x\":{\"diagram\":\"digraph {\\n\\ngraph [layout = \\\"dot\\\",\\n       outputorder = \\\"edgesfirst\\\",\\n       bgcolor = \\\"white\\\",\\n       splines = \\\"line\\\",\\n       overlap = \\\"false\\\"]\\n\\nnode [fontname = \\\"Helvetica\\\",\\n      fontsize = \\\"10\\\",\\n      shape = \\\"rect\\\",\\n      fixedsize = \\\"false\\\",\\n      width = \\\"0.5\\\",\\n      style = \\\"rounded\\\",\\n      fillcolor = \\\"aliceblue\\\",\\n      color = \\\"gray\\\",\\n      fontcolor = \\\"black\\\",\\n      margin = \\\".25, 0\\\"]\\n\\nedge [fontname = \\\"Helvetica\\\",\\n     fontsize = \\\"8\\\",\\n     len = \\\"1.5\\\",\\n     color = \\\"gray80\\\",\\n     arrowsize = \\\"0.5\\\",\\n     tailport = \\\"s\\\",\\n     headport = \\\"n\\\",\\n     concentrate = \\\"false\\\",\\n     constraint = \\\"true\\\"]\\n\\n  \\\"1\\\" [label = <<BR/><B>Base Dataset<\\/B><BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/>the_data<BR/> >] \\n  \\\"2\\\" [label = <<BR/><B>Variables<\\/B><BR/><BR/>2 sets<BR/>(2*3 = 6)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"3\\\" [label = <<BR/><B>dvs<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; dv1<BR ALIGN=\\\"LEFT\\\"/>&#x2022; dv2<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>ivs<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv1<BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv2<BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv3<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"4\\\" [label = <<BR/><B>Filters<\\/B><BR/><BR/>3 sets<BR/>(2*2*2 = 8)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"5\\\" [label = <<BR/><B>include1<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; include1 equals 0<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include1 is any value<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>include2<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; include2 does not equal 3<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include2 is any value<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>include3<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; z-scored include3 is bigger than -2.5<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include3 is any value<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"6\\\" [label = <<BR/><B>48 datasets<\\/B><BR/>filters (8) * variables (6)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"7\\\" [label = <<BR/><B>linear model<\\/B><BR/>lm({dvs} ~ {ivs} * mod)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"8\\\" [label = <<BR/><B>48 fitted models<\\/B><BR ALIGN=\\\"LEFT\\\"/>2*2*2*2*3*1<BR/> >] \\n  \\\"1\\\" [label = <<BR/><B>Base Dataset<\\/B><BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/>the_data<BR/> >] \\nsubgraph{rank = same\\n  \\\"2\\\" [label = <<BR/><B>Variables<\\/B><BR/><BR/>2 sets<BR/>(2*3 = 6)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"3\\\" [label = <<BR/><B>dvs<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; dv1<BR ALIGN=\\\"LEFT\\\"/>&#x2022; dv2<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>ivs<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv1<BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv2<BR ALIGN=\\\"LEFT\\\"/>&#x2022; iv3<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"4\\\" [label = <<BR/><B>Filters<\\/B><BR/><BR/>3 sets<BR/>(2*2*2 = 8)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"5\\\" [label = <<BR/><B>include1<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; include1 equals 0<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include1 is any value<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>include2<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; include2 does not equal 3<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include2 is any value<BR ALIGN=\\\"LEFT\\\"/><BR ALIGN=\\\"LEFT\\\"/><B>include3<\\/B><BR ALIGN=\\\"LEFT\\\"/>&#x2022; z-scored include3 is bigger than -2.5<BR ALIGN=\\\"LEFT\\\"/>&#x2022; include3 is any value<BR ALIGN=\\\"LEFT\\\"/> >] }\\n\\n  \\\"6\\\" [label = <<BR/><B>48 datasets<\\/B><BR/>filters (8) * variables (6)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"7\\\" [label = <<BR/><B>linear model<\\/B><BR/>lm({dvs} ~ {ivs} * mod)<BR ALIGN=\\\"LEFT\\\"/> >] \\n  \\\"8\\\" [label = <<BR/><B>48 fitted models<\\/B><BR ALIGN=\\\"LEFT\\\"/>2*2*2*2*3*1<BR/> >] \\n\\\"3\\\"->\\\"2\\\" [color = \\\"purple\\\", style = \\\"invis\\\", style = \\\"invis\\\", style = \\\"invis\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"2\\\"->\\\"4\\\" [color = \\\"purple\\\", style = \\\"invis\\\", style = \\\"invis\\\", style = \\\"invis\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"4\\\"->\\\"5\\\" [color = \\\"purple\\\", style = \\\"invis\\\", style = \\\"invis\\\", style = \\\"invis\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"1\\\"->\\\"4\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"1\\\"->\\\"2\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"3\\\"->\\\"2\\\" [color = \\\"gray80\\\", style = \\\"solid\\\", arrowhead = \\\"none\\\", arrowtail = \\\"none\\\", headport = \\\"w\\\", tailport = \\\"e\\\"] \\n\\\"4\\\"->\\\"5\\\" [color = \\\"gray80\\\", style = \\\"solid\\\", arrowhead = \\\"none\\\", arrowtail = \\\"none\\\", headport = \\\"w\\\", tailport = \\\"e\\\"] \\n\\\"2\\\"->\\\"6\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"4\\\"->\\\"6\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"6\\\"->\\\"7\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n\\\"7\\\"->\\\"8\\\" [color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", color = \\\"gray80\\\", headport = \\\"n\\\", tailport = \\\"s\\\"] \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}"},{"path":"https://ethan-young.github.io/multitool/reference/detect_multiverse_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect total number of analysis pipelines — detect_multiverse_n","title":"Detect total number of analysis pipelines — detect_multiverse_n","text":"Detect total number analysis pipelines","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_multiverse_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect total number of analysis pipelines — detect_multiverse_n","text":"","code":"detect_multiverse_n(.grid, include_models = TRUE)"},{"path":"https://ethan-young.github.io/multitool/reference/detect_multiverse_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect total number of analysis pipelines — detect_multiverse_n","text":".grid full decision grid created expand_decisions include_models Whether count alternative models one add_model() call.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_multiverse_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect total number of analysis pipelines — detect_multiverse_n","text":"numeric, total number unique analyis pipelines","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_multiverse_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect total number of analysis pipelines — detect_multiverse_n","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  detect_multiverse_n(full_pipeline) #> [1] 48"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_filters.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect total number of filtering expressions your pipelines — detect_n_filters","title":"Detect total number of filtering expressions your pipelines — detect_n_filters","text":"Detect total number filtering expressions pipelines","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_filters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect total number of filtering expressions your pipelines — detect_n_filters","text":"","code":"detect_n_filters(.grid)"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_filters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect total number of filtering expressions your pipelines — detect_n_filters","text":".grid full decision grid created expand_decisions","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_filters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect total number of filtering expressions your pipelines — detect_n_filters","text":"numeric, total number filtering expressions","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_filters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect total number of filtering expressions your pipelines — detect_n_filters","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  detect_n_filters(full_pipeline) #> [1] 8"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect total number of models in your pipelines — detect_n_models","title":"Detect total number of models in your pipelines — detect_n_models","text":"Detect total number models pipelines","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect total number of models in your pipelines — detect_n_models","text":"","code":"detect_n_models(.grid)"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect total number of models in your pipelines — detect_n_models","text":".grid full decision grid created expand_decisions","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect total number of models in your pipelines — detect_n_models","text":"numeric, total number unique models","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect total number of models in your pipelines — detect_n_models","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  detect_n_models(full_pipeline) #> [1] 1"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect total number of variable sets in your pipelines — detect_n_variables","title":"Detect total number of variable sets in your pipelines — detect_n_variables","text":"Detect total number variable sets pipelines","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect total number of variable sets in your pipelines — detect_n_variables","text":"","code":"detect_n_variables(.grid)"},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect total number of variable sets in your pipelines — detect_n_variables","text":".grid full decision grid created expand_decisions","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect total number of variable sets in your pipelines — detect_n_variables","text":"numeric, total number unique variable sets","code":""},{"path":"https://ethan-young.github.io/multitool/reference/detect_n_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect total number of variable sets in your pipelines — detect_n_variables","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  detect_n_variables(full_pipeline) #> [1] 6"},{"path":"https://ethan-young.github.io/multitool/reference/expand_decisions.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"Expand set multiverse decisions possible combinations","code":""},{"path":"https://ethan-young.github.io/multitool/reference/expand_decisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"","code":"expand_decisions(.grid)"},{"path":"https://ethan-young.github.io/multitool/reference/expand_decisions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":".grid ddata.frame produced calling series add_* functions.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/expand_decisions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"nested data.frame containing combinations arbitrary decisions multiverse analysis. Decision types become list columns matching type decisions called along pipeline (e.g., filters, variables, etc.). decisions containing glue syntax populated relevant information.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/expand_decisions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a set of multiverse decisions into all possible combinations — expand_decisions","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(\"no covariates\", lm({dvs} ~ {ivs} * {mods})) |>   add_model(\"with covariates\", lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  full_pipeline #> # A tibble: 432 × 9 #>    decision variables        filters  preprocess models   postprocess corrs    #>    <chr>    <list>           <list>   <list>     <list>   <list>      <list>   #>  1 1        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  2 2        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  3 3        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  4 4        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  5 5        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  6 6        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  7 7        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  8 8        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #>  9 9        <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #> 10 10       <tibble [1 × 3]> <tibble> <tibble>   <tibble> <tibble>    <tibble> #> # ℹ 422 more rows #> # ℹ 2 more variables: summary_stats <list>, cron_alphas <list>"},{"path":"https://ethan-young.github.io/multitool/reference/icar_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Early Life Adversity and Cognitive Ability — icar_data","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"unpublished experiment looking effect priming economic threat childhood adversity International Cognitive Ability Resource (ICAR) scores","code":""},{"path":"https://ethan-young.github.io/multitool/reference/icar_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"","code":"icar_data"},{"path":"https://ethan-young.github.io/multitool/reference/icar_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"data frame 413 rows 63 variables: sample Lab online subsample condition Experimental condition, 0 = control (computer crash); 1 = experimental (recession) dems_gender gender identify ? dems_age AGE years? (e.g. 25) dems_ethnicity ethnicity? dems_edu highest level education completed? dems_us_born grow United States? dems_english_native grow speaking English? dems_fluency fluent English language? dems_lang English language know best? child_unp_obj1 many times parents legal guardians change jobs occupational status? child_unp_obj2 many times move change residence (move different house, neighborhood, city, state)? child_unp_obj3 many times changes familial circumstances? (divorce, parents starting new relationships, parents leaving home) child_unp_changes1 Economic status: child_unp_changes2 Family environment: child_unp_changes3 childhood neighborhood environment: child_unp_changes4 childhood school environment: child_unp_subj1 family life generally inconsistent unpredictable day--day. child_unp_subj2 parent(s) frequently arguments fights people childhood. child_unp_subj3 parents difficult divorce separation time. child_unp_subj4 People often moved house pretty random basis. child_unp_subj5 woke , often know happen house day. child_unp_subj6 family environment often tense \"edge\". child_unp_subj7 Things often chaotic house. child_unp_subj8 hard time knowing parent(s) people house going say. child_ses_subj1 grew relatively wealthy neighborhood. child_ses_subj2 felt relatively wealthy compared kids. child_ses_subj3 family usually enough money things growing . child_income household income growing ? unp_obj_mean Childhood unpredictability (objective) mean score unp_changes_mean Childhood unpredictability (changes) mean score unp_subj_mean Childhood unpredictability (subjective) mean score ses_subj_mean Childhood socioeconomic status (objective) mean score vr_04 Verbal reasoning item 4 vr_17 Verbal reasoning item 17 ln_07 Letter-number item 7 ln_58 Letter-number item 58 mx_45 Matrix reasoning item 45 mx_46 Matrix reasoning item 46 r3d_06 Mental Rotation item 6 r3d_08 Mental Rotation item 8 vr_16 Verbal reasoning item 16 vr_19 Verbal reasoning item 19 ln_33 Letter-number item 33 ln_34 Letter-number item 34 mx_47 Matrix reasoning item 47 mx_55 Matrix reasoning item 55 r3d_03 Mental Rotation item 3 r3d_04 Mental Rotation item 4 ln_sum Total score (4) letter-number items mx_sum Total score (4) matrix reasoning items vr_sum Total score (4) verbal reasoning items r3d_sum Total score (4) 3d rotation items icar_sum Total score (16) ICAR battery time_condition Time seconds experimental manipulation displayed (60 seconds) time_icar Time seconds took complete whole ICAR battery time_ln Time seconds took complete lettter-number items time_mx Time seconds took complete matrix reasoning items time_vr Time seconds took complete verbal reasoning items time_r3d Time seconds took complete 3d rotation items att_interrupt ever interrupted anyone anything time spent survey? att_one_sitting complete survey one sitting? att_getup ever get leave computer study (reason)?","code":""},{"path":"https://ethan-young.github.io/multitool/reference/icar_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Early Life Adversity and Cognitive Ability — icar_data","text":"data_URL","code":""},{"path":"https://ethan-young.github.io/multitool/reference/icar_data_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data frame contains information documentation ICAR dataset provides use session.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/icar_data_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"","code":"icar_data_codebook"},{"path":"https://ethan-young.github.io/multitool/reference/icar_data_codebook.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data frame 63 rows 3 variables: var_name name variable data var_label brief description variable var_values explanation values labels applicable","code":""},{"path":"https://ethan-young.github.io/multitool/reference/icar_data_codebook.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"A variable, variable label, and value label codebook for the ICAR dataset — icar_data_codebook","text":"data_URL","code":""},{"path":"https://ethan-young.github.io/multitool/reference/report_universe_console.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a 'universe' console report — report_universe_console","title":"Create a 'universe' console report — report_universe_console","text":"Create 'universe' console report","code":""},{"path":"https://ethan-young.github.io/multitool/reference/report_universe_console.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a 'universe' console report — report_universe_console","text":"","code":"report_universe_console(multiverse, decision_num)"},{"path":"https://ethan-young.github.io/multitool/reference/report_universe_console.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a 'universe' console report — report_universe_console","text":"multiverse tibble created run_multiverse decision_num decision set create report ","code":""},{"path":"https://ethan-young.github.io/multitool/reference/report_universe_console.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a 'universe' console report — report_universe_console","text":"","code":"if (FALSE) { my_multi_results <- run_multiverse(my_grid, .df)  report_universe_console(my_multi_verse, .df, 1) }"},{"path":"https://ethan-young.github.io/multitool/reference/reveal.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal the contents of a multiverse analysis — reveal","title":"Reveal the contents of a multiverse analysis — reveal","text":"Reveal contents multiverse analysis","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal the contents of a multiverse analysis — reveal","text":"","code":"reveal(.multi, .what, .which = NULL, .unpack_specs = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/reveal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal the contents of a multiverse analysis — reveal","text":".multi multiverse list-column tibble produced run_multiverse. .name list-column like unpack .sub-list columns like unpack .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal the contents of a multiverse analysis — reveal","text":"unnested part multiverse requested. usually contains particular estimates statistics like analyze decision grid specified.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal the contents of a multiverse analysis — reveal","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal results of the linear model the_multiverse |> reveal(lm_fitted, matches(\"tidy\"), .unpack_specs = TRUE) }"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_alphas.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"Reveal set multiverse cronbach's alpha statistics","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_alphas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"","code":"reveal_alphas(.multi, .which, .unpack_specs = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_alphas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":".multi multiverse list-column tibble produced run_multiverse. .specific name alphas .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_alphas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"unnested set correlations per decision multiverse.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_alphas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of multiverse cronbach's alpha statistics — reveal_alphas","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal multiverse reliability analyses the_multiverse |> reveal(cron_alphas_computed) }"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_corrs.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of multiverse correlations — reveal_corrs","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"Reveal set multiverse correlations","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_corrs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"","code":"reveal_corrs(.multi, .which, .unpack_specs = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_corrs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of multiverse correlations — reveal_corrs","text":".multi multiverse list-column tibble produced run_multiverse. .specific name correlations requested .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_corrs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"unnested set correlations per decision multiverse.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_corrs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of multiverse correlations — reveal_corrs","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal correlations among predictor across decision set the_multiverse |> reveal_corrs(predictors_rs) }"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"Reveal set summary statistics multiverse analysis","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"","code":"reveal_summary_stats(.multi, .which, .unpack_specs = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/reveal_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":".multi multiverse list-column tibble produced run_multiverse. .specific name summary statistics .unpack_specs logical, whether unnest specifications built multiverse grid. Defaults FALSE.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"unnested set summary statistics per decision multiverse.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/reveal_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reveal a set of summary statistics from a multiverse analysis — reveal_summary_stats","text":"","code":"if (FALSE) { library(tidyverse) library(multitool)  # Simulate some data the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # Decision pipeline full_pipeline <-   the_data |>   add_filters(include1 == 0,include2 != 3,include2 != 2,scale(include3) > -2.5) |>   add_variables(\"ivs\", iv1, iv2, iv3) |>   add_variables(\"dvs\", dv1, dv2) |>   add_variables(\"mods\", starts_with(\"mod\")) |>   add_preprocess(process_name = \"scale_iv\", 'mutate({ivs} = scale({ivs}))') |>   add_preprocess(process_name = \"scale_mod\", mutate({mods} := scale({mods}))) |>   add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>   add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>   add_correlations(\"predictors\", matches(\"iv|mod|cov\"), focus_set = c(cov1,cov2)) |>   add_correlations(\"outcomes\", matches(\"dv|mod\"), focus_set = matches(\"dv\")) |>   add_cron_alpha(\"unp_scale\", c(iv1,iv2,iv3)) |>   add_cron_alpha(\"vio_scale\", starts_with(\"mod\")) |>   add_model(lm({dvs} ~ {ivs} * {mods})) |>   add_model(lm({dvs} ~ {ivs} * {mods} + cov1)) |>   add_postprocess(\"aov\", aov()) |>   expand_decisions()  # Run the whole multiverse the_multiverse <- run_multiverse(full_pipeline[1:10,])  # Reveal summary statistics the_multiverse |> reveal_summary_stats(iv_stats) }"},{"path":"https://ethan-young.github.io/multitool/reference/run_descriptives.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","title":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","text":"Run multiverse-style descriptive analysis based complete decision grid","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_descriptives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","text":"","code":"run_descriptives(.pipeline, show_progress = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/run_descriptives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","text":".pipeline tibble produced series add_* calls. Importantly, needs pre-expanded pipeline descriptive analyses change underlying cases change. Thus, filtering decisions used internally expanded calculating various descriptive analyses. show_progress logical, whether show progress bar running.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_descriptives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","text":"single tibble containing tidied results descriptive analyses specified","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_descriptives.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a multiverse-style descriptive analysis based on a complete decision grid — run_descriptives","text":"","code":"if (FALSE) { run_descriptives(pipeline) }"},{"path":"https://ethan-young.github.io/multitool/reference/run_multiverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a multiverse based on a complete decision grid — run_multiverse","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"Run multiverse based complete decision grid","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_multiverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"","code":"run_multiverse(.grid, save_model = FALSE, ncores = 1, show_progress = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/run_multiverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":".grid tibble produced expand_decisions save_model logical, indicates whether save model object entirety. default FALSE model objects usually large hood, parameters performance used summarize useful model information. ncores numeric. number cores want use parallel processing. show_progress logical, whether show progress bar running.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_multiverse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"single tibble containing tidied results model post-processing tests/tasks. unique test (e.g., lm aov called lm), list column function name created parameters performance warnings messages printed fitting models. Internally, modeling post-processing functions checked see tidy glance methods available. , summary called instead.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_multiverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a multiverse based on a complete decision grid — run_multiverse","text":"","code":"if (FALSE) { run_multiverse(grid) }"},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a single set of arbitrary decisions and save the result — run_universe_model","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"Run single set arbitrary decisions save result","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"","code":"run_universe_model(.grid, decision_num, save_model = FALSE)"},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":".grid tibble produced expand_decisions decision_num single integer 1 nrow(grid) indicating specific decision set run save_model logical, indicates whether save model object entirety. default FALSE model objects usually large hood, tidy glance used summarize useful model information.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"single row tibble containing decision, code ran, results, notes (e.g., warnings messages).","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a single set of arbitrary decisions and save the result — run_universe_model","text":"","code":"if (FALSE) { run_universe(.grid, .df, decision_num) }"},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute summary statistics for a single decision set — run_universe_summary_stats","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"Compute summary statistics single decision set","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"","code":"run_universe_summary_stats(.grid, decision_num)"},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":".grid data.frame resulting expand_decisions decision_num index particular decision set want run","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_summary_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"single row data.frame list columns containing summary statistics specified .grid","code":""},{"path":"https://ethan-young.github.io/multitool/reference/run_universe_summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute summary statistics for a single decision set — run_universe_summary_stats","text":"","code":"library(tidyverse) library(multitool)  the_data <-   data.frame(     id   = 1:500,     iv1  = rnorm(500),     iv2  = rnorm(500),     iv3  = rnorm(500),     mod1 = rnorm(500),     mod2 = rnorm(500),     mod3 = rnorm(500),     cov1 = rnorm(500),     cov2 = rnorm(500),     dv1  = rnorm(500),     dv2  = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  summary_stats_grid <-   the_data |>     add_variables(\"ivs\", iv1, iv2, iv3) |>     add_variables(\"dvs\", dv1, dv2) |>     add_variables(\"mods\", starts_with(\"mod\")) |>     add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>     add_summary_stats(\"iv_stats\", starts_with(\"iv\"), c(\"mean\", \"sd\")) |>     add_summary_stats(\"dv_stats\", starts_with(\"dv\"), c(\"skewness\", \"kurtosis\")) |>     expand_decisions()  run_universe_summary_stats(summary_stats_grid, decision_num  = 12) #> Error in map2(.x, .y, .f, ...): ℹ In index: 1. #> ℹ With name: iv_stats. #> Caused by error: #> ! object 'the_data' not found"},{"path":"https://ethan-young.github.io/multitool/reference/show_code_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Show multiverse data code pipelines — show_code_filter","title":"Show multiverse data code pipelines — show_code_filter","text":"show_code* function self-explanatory - indicate along multiverse pipeline extract code. goal functions create window multiverse decision set context/results allow user inspect specific decisions straight code produced .","code":""},{"path":"https://ethan-young.github.io/multitool/reference/show_code_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show multiverse data code pipelines — show_code_filter","text":"","code":"show_code_filter(.grid, decision_num, copy = F)  show_code_preprocess(.grid, decision_num, copy = F)  show_code_model(.grid, decision_num, copy = F)  show_code_postprocess(.grid, decision_num, copy = F)  show_code_summary_stats(.grid, decision_num, copy = F)  show_code_corrs(.grid, decision_num, copy = F)  show_code_cron_alpha(.grid, decision_num, copy = F)"},{"path":"https://ethan-young.github.io/multitool/reference/show_code_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show multiverse data code pipelines — show_code_filter","text":".grid full decision grid created expand_decisions decision_num numeric. Indicates 'universe' multiverse show underlying code. copy logical. Whether copy pipeline code clipboard using write_clip.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/show_code_filter.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Show multiverse data code pipelines — show_code_filter","text":"show_code_preprocess(): Show code preprocessing stage show_code_model(): Show code modeling stage show_code_postprocess(): Show code post-processing stage show_code_summary_stats(): Show code computing summary statistics show_code_corrs(): Show code computing correlations show_code_cron_alpha(): Show code computing correlations","code":""},{"path":"https://ethan-young.github.io/multitool/reference/summarize_filter_ns.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","title":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","text":"Summarize samples sizes unique filtering expression","code":""},{"path":"https://ethan-young.github.io/multitool/reference/summarize_filter_ns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","text":"","code":"summarize_filter_ns(.grid)"},{"path":"https://ethan-young.github.io/multitool/reference/summarize_filter_ns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","text":".grid full decision grid created expand_decisions","code":""},{"path":"https://ethan-young.github.io/multitool/reference/summarize_filter_ns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","text":"tibble row representing filtering expression four columns: filter_expression, variable, n_retained, n_excluded.","code":""},{"path":"https://ethan-young.github.io/multitool/reference/summarize_filter_ns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize samples sizes for each unique filtering expression — summarize_filter_ns","text":"","code":"library(tidyverse) library(multitool)  # create some data the_data <-   data.frame(     id  = 1:500,     iv1 = rnorm(500),     iv2 = rnorm(500),     iv3 = rnorm(500),     mod = rnorm(500),     dv1 = rnorm(500),     dv2 = rnorm(500),     include1 = rbinom(500, size = 1, prob = .1),     include2 = sample(1:3, size = 500, replace = TRUE),     include3 = rnorm(500)   )  # create a pipeline blueprint full_pipeline <-   the_data |>   add_filters(include1 == 0, include2 != 3, scale(include3) > -2.5) |>   add_variables(var_group = \"ivs\", iv1, iv2, iv3) |>   add_variables(var_group = \"dvs\", dv1, dv2) |>   add_model(\"linear model\", lm({dvs} ~ {ivs} * mod))  summarize_filter_ns(full_pipeline) #> Warning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0. #> ℹ Please use one dimensional logical vectors instead. #> ℹ The deprecated feature was likely used in the multitool package. #>   Please report the issue to the authors. #> # A tibble: 6 × 4 #>   filter_expression              variable n_retained n_excluded #>   <chr>                          <chr>         <int>      <int> #> 1 include1 == 0                  include1        445         55 #> 2 include1 %in% unique(include1) include1        500          0 #> 3 include2 != 3                  include2        326        174 #> 4 include2 %in% unique(include2) include2        500          0 #> 5 scale(include3) > -2.5         include3        494          6 #> 6 include3 %in% unique(include3) include3        500          0"}]
